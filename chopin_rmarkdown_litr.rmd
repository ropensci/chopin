---
title: "CHOPIN: Computation for Climate and Health research On Parallelized INfrastructure: ``r params$package_name``"
author: "Insang Song"
date: "2024-03-11"
knit: litr::render
output: litr::litr_html_document
params:
  package_name: "chopin" # <-- change this to your package name
  package_parent_dir: "." # <-- relative to this file's location
---

<!-- This Rmd file contains all the code needed to define an R package.  Press "Knit" in RStudio or more generally run `litr::render("name-of-this-file.Rmd")` to generate the R package.  Remember that when you want to modify anything about the R package, you should modify this document rather than the package that is outputted.
-->

## Package setup

We start by specifying the information needed in the DESCRIPTION file of the R package.

```{r package-setup, message=FALSE, results='hide'}
usethis::create_package(
  path = ".",
  fields = list(
    Package = params$package_name,
    Version = "0.5.0.20240311",
    Title = "CHOPIN: Computation for Climate and Health research On Parallelized INfrastructure",
    Description = "It enables users with basic understanding on geospatial data and sf and terra functions to parallelize geospatial operations for geospatial exposure assessment modeling and covariate computation. Parallelization is done by dividing large datasets into sub-regions with regular grids and data's own hierarchy. A computation over the large number of raster files can be parallelized with a chopin function as well.",
    `Authors@R` = c(
      person(
        given = "Insang",
        family = "Song",
        email = "geoissong@gmail.com",
        role = c("aut", "cre"),
        comment = c(ORCID = "0000-0001-8732-3256")
      ),
      person(
        given = "Kyle",
        family = "Messier",
        role = c("aut", "ctb"),
        comment = c(ORCID = "0000-0001-9508-9623")
      )
    ),
    LazyData = "true",
    LazyDataCompression = "xz",
    Depends = "R (>= 4.1)",
    URL = "https://github.com/Spatiotemporal-Exposures-and-Toxicology/chopin",
    BugReports = "https://github.com/Spatiotemporal-Exposures-and-Toxicology/chopin/issues"
  )
)
#usethis::use_build_ignore("rds$", escape = FALSE)
usethis::use_build_ignore(c("tests"), escape = FALSE)
usethis::use_build_ignore(c(".github"), escape = FALSE)
usethis::use_build_ignore(c("tools"), escape = FALSE)
usethis::use_build_ignore(c("figure"), escape = FALSE)
usethis::use_build_ignore(c("containers"), escape = FALSE)
usethis::use_build_ignore(c("input"), escape = FALSE)
usethis::use_build_ignore(c("\\*_litr.Rmd"), escape = FALSE)
usethis::use_build_ignore(c("\\*_litr.rmd"), escape = FALSE)
usethis::use_build_ignore(c("\\*.yml"), escape = FALSE)
# usethis::use_build_ignore(c("CODE_OF_CONDUCT.md"), escape = FALSE)
usethis::use_build_ignore(c("\\*.html"), escape = FALSE)

usethis::use_package("dplyr", min_version = "1.1.0")
usethis::use_package("sf", min_version = "1.0-10")
usethis::use_package("terra", min_version = "1.7-18")
usethis::use_package("stars", min_version = "0.6-0")
usethis::use_package("rlang", min_version = "0.4.9")
usethis::use_package("methods")
usethis::use_package("exactextractr", min_version = "0.8.2")
usethis::use_package("future")
usethis::use_package("future.apply")
usethis::use_package("covr", "Suggests")
# usethis::use_package("lobstr", "Suggests")
usethis::use_package("testthat", "Suggests")
usethis::use_package("units", "Suggests")
usethis::use_package("doParallel", "Suggests")
usethis::use_package("doFuture")
usethis::use_package("future.batchtools", "Suggests")
usethis::use_package("igraph")
usethis::use_package("withr", "Suggests")
usethis::use_package("knitr", "Suggests")
usethis::use_mit_license()
usethis::use_code_of_conduct("geoissong@gmail.com")
# usethis::use_pkgdown()
# https://cran.r-project.org/web/packages/roxygen2/vignettes/rd-formatting.html#lists
usethis::use_roxygen_md()
# usethis::use_pkgdown_github_pages()

# usethis::use_vignette("1_setting_distribution.rmd")
```
<!--
-->

```{r}
# file.copy("../tools/readme-source/README.Rmd", "./README.Rmd")
# file.copy("../tools/pkgdown-source/_pkgdown.yml", "./_pkgdown.yml")
usethis::use_directory("inst")
usethis::use_directory("inst/extdata")
testfiles <- list.files("../tools/testdata", pattern = NULL, full.names = FALSE)
testfiles <- grep("(prediction_grid)", testfiles, perl = TRUE, value = TRUE, invert = TRUE)
sapply(testfiles, \(x) file.copy(file.path("../tools/testdata", x), file.path("./inst/extdata", x)))
```


### Test data generation
```{r generate-test-data, eval=FALSE, include=FALSE}
OPENTOPO_CREDENTIAL <- ""

pkgs <- c("sf", "terra", "dplyr", "spatstat.random", "elevatr")
invisible(sapply(pkgs, library, character.only = TRUE, quietly = TRUE))
elevatr::set_opentopo_key(OPENTOPO_CREDENTIAL)
sf::sf_use_s2(FALSE)
set.seed(300)
ncpath <- system.file("shape/nc.shp", package = "sf")
ncpoly <- sf::read_sf(ncpath) %>%
  sf::st_transform("EPSG:5070")

ncrandpoint <- sf::st_sample(type = "Thomas", x = ncpoly, size = 300, mu = 0.00005, scale = 16000, kappa = 0.00005) %>%
  mutate(pid = seq_len(nrow(.))) %>%
  select(-label)
sf::st_crs(ncrandpoint) <- "EPSG:5070"
saveRDS(ncrandpoint, "./tests/testdata/nc_random_point.rds")

ncrast <- elevatr::get_elev_raster(ncpoly, z = 9, src = "srtm15plus", prj = terra::crs("EPSG:5070"))
ncrastt <- terra::rast(ncrast)
ncrastw <- terra::wrap(ncrastt)
# terra::writeRaster(ncrastt, "./tests/testdata/nc_srtm15_otm.tif", gdal=c("COMPRESS=DEFLATE"), overwrite = TRUE)
saveRDS(ncrastw, "./tests/testdata/nc_srtm15_otm.rds", compress = "xz")

library(nhdplusTools)
huc08s <- get_huc(AOI = sf::st_union(ncpoly), buffer = 10000L, type = "huc08")
library(readxl)

ecors <- list.files(path = "/Users/songi2/Documents/Ecoregions/",
  pattern = "*.xlsx", full.names = TRUE) %>%
  .[-length(.)] %>%
  lapply(\(x) readxl::read_excel(x, sheet = 4)) %>%
  do.call(bind_rows, .)

huc08sadd <- left_join(huc08s, ecors, by = c("huc8" = "Hydrologic Unit Code 8-Digit (HUC8)")) %>%
  select(-1:-12, -globalid)

huc08sadd
saveRDS(huc08sadd, "./tests/testdata/huc08_nc.rds", compress = "xz")

usethis::use_news_md()
```


### Vignettes 1

```{r vig1, eval = TRUE}
litr::add_vignettes("../tools/vignettes-sources/v00_good_practice_parallelization.Rmd")
```

### Vignettes 2

```{r vig2, eval = TRUE}
litr::add_vignettes("../tools/vignettes-sources/v01_par_make_gridset.Rmd")
```


### Vignettes 3

```{r vig-climate, eval = TRUE}
litr::add_vignettes("../tools/vignettes-sources/v02_climate_examples.Rmd")
if (!dir.exists("./vignettes/figures")) {
  dir.create("./vignettes/figures")
}
file.copy("../tools/vignettes-sources/figures/climate-ex-grid-comparison.png", "./vignettes/figures/climate-ex-grid-comparison.png")
```


### Add data
```{r add-data}
prediction_grid <- readRDS("../tools/testdata/prediction_grid.rds")
usethis::use_data(prediction_grid, compress = "xz")
ncpoints <- readRDS("../tools/testdata/clpnts.rds")
usethis::use_data(ncpoints, compress = "xz")
```

```{r doc-data}
#' Regular grid points in the mainland United States at 1km spatial resolution
#' @family Dataset
#' @format A data frame with 8,092,995 rows and three variables:
#' \describe{
#' \item{site_id}{Unique point identifier. Arbitrarily generated.}
#' \item{lon}{Longitude}
#' \item{lat}{Latitude}
#' }
#' @note Coordinates are in EPSG:5070 (Conus Albers Equal Area)
#' @source Mainland United States polygon was obtained from
#' the US Census Bureau.
#' @examples
#' data("prediction_grid", package = "chopin")
"prediction_grid"

```

```{r doc-ncpoints}
#' Mildly clustered points in North Carolina, United States
#' @family Dataset
#' @format A data frame with 2,304 rows and two variables:
#' \describe{
#' \item{X}{X coordinate}
#' \item{Y}{Y coordinate}
#' }
#' @note Coordinates are in EPSG:5070 (Conus Albers Equal Area)
#' @source sf package data `nc`
#' @examples
#' data("ncpoints", package = "chopin")
"ncpoints"

```

# Now to the package itself

### Create functions


```{r testcheck, eval = FALSE, include = FALSE}

repan <- function(d, bw) return ((3/4) * (1 - ((d/bw)^2)))

bench::mark(
    repanRun = repan(300, 1000),
    # cepanRun = kernelCpp(300, 1000, "epanechnikov"),
    rrkrun = kernelfunction("epanechnikov", 300, 1000),
    iterations = 1000L
 
)

```
```{r, send_to = "R/processing.R"}
#' Kernel functions
#' @family Macros for calculation
#' @param kernel Kernel type. One of
#' `"uniform"`, `"quartic"`, `"triweight"`, and `"epanechnikov"`
#' @param d Distance
#' @param bw Bandwidth of a kernel
#' @returns numeric. Kernel weights.
#' @references \href{https://github.com/JanCaha/SpatialKDE}{SpatialKDE source}
#' @examples
#' v_dist <- c(1, 10, 100, 25, 50, 0.1)
#' bw_dist1 <- 1
#' bw_dist2 <- 10
#' kernelfunction(v_dist, bw_dist1, "uniform")
#' kernelfunction(v_dist, bw_dist1, "quartic")
#' kernelfunction(v_dist, bw_dist1, "triweight")
#' kernelfunction(v_dist, bw_dist1, "epanechnikov")
#' kernelfunction(v_dist, bw_dist2, "uniform")
#' kernelfunction(v_dist, bw_dist2, "quartic")
#' kernelfunction(v_dist, bw_dist2, "triweight")
#' kernelfunction(v_dist, bw_dist2, "epanechnikov")
#' @export
kernelfunction <-
  function(
    d,
    bw,
    kernel = c("uniform", "quartic", "triweight", "epanechnikov")
  ) {
    kernel <- match.arg(kernel)
    if (kernel == "uniform") {
      d <- ifelse(d > bw, 0, 0.5)
    } else {
      d <- ifelse(d > bw, bw, d)
    }
    switch(kernel,
      uniform = d,
      quartic = (15 / 16) * (1 - ((d / bw)^2))^2,
      triweight = 1 - ((d / bw) ^ 3),
      epanechnikov = (3 / 4) * (1 - ((d / bw)^2))
    )

  }
```


```{r test-kernel-function, eval = FALSE}
testthat::test_that("Kernel functions work okay", {
  testthat::expect_error(kernelfunction(10, 100, "hyperbolic"))
  testthat::expect_no_error(kernelfunction(10, 100, "uniform"))
  testthat::expect_no_error(kernelfunction(10, 100, "quartic"))
  testthat::expect_no_error(kernelfunction(10, 100, "triweight"))
  testthat::expect_no_error(kernelfunction(10, 100, "epanechnikov"))
})

```


```{r, send_to = "R/check.R"}
#' @title Return the package the input object is based on
#' @family Helper functions
#' @description Detect whether the input object is sf or Spat* object.
#' @author Insang Song
#' @param input Spat* in terra or sf object.
#' @returns A character object; one of `"terra"` and `"sf"`
#' @examples
#' library(sf)
#' library(terra)
#' options(sf_use_s2 = FALSE)
#'
#' nc_path <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc_sf <- sf::st_read(nc_path)
#' dep_check(nc_sf)
#' nc_vect <- terra::vect(nc_sf)
#' dep_check(nc_vect)
#' ## END OF EXAMPLE
#' @export
dep_check <- function(input) {
  if (!any(class(input) %in% c("sf", "stars", "SpatVector", "SpatRaster"))) {
    stop("Input should be one of sf or Spat* object.\n")
  }
  if (methods::is(input, "SpatVector") || methods::is(input, "SpatRaster")) {
    return("terra")
  }
  return("sf")
}


#' Return the input's GIS data model type
#' @family Helper functions
#' @description This function returns one of 'vector' or 'raster'
#' depending on the input class.
#' @param input Spat*/sf/stars object.
#' @note Although \code{stars} object is a little ambiguous
#' whether to classify vector or raster,
#' it will be considered raster in this package.
#' @author Insang Song
#' @returns character(1). One of `"vector"` or `"raster"`.
#' @examples
#' library(sf)
#' library(terra)
#' options(sf_use_s2 = FALSE)
#'
#' nc_path <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc_sf <- sf::st_read(nc_path)
#' datamod(nc_sf)
#'
#' ra_path <- system.file("ex/elev.tif", package = "terra")
#' ra <- terra::rast(ra_path)
#' datamod(ra)
#' @importFrom methods is
#' @export
datamod <- function(input) {
  if (!any(class(input) %in% c("sf", "stars", "SpatVector", "SpatRaster"))) {
    stop("Input should be one of sf or Spat* object.\n")
  }
  if (any(methods::is(input, "SpatVector"), methods::is(input, "sf"))) {
    return("vector")
  }
  if (any(methods::is(input, "SpatRaster"), methods::is(input, "stars"))) {
    return("raster")
  }
}
```

```{r test-packbound, send_to = "tests/testthat/test-check.R"}
testthat::test_that("What package does the input object belong?",
  {
    withr::local_package("stars")
    withr::local_package("terra")
    withr::local_options(list(sf_use_s2 = FALSE))
    bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
    bcsd_stars <- stars::read_stars(bcsd_path)

    packbound_stars <- dep_check(bcsd_stars)
    sprast_bcsd <- terra::rast(bcsd_path)
    packbound_terra <- dep_check(sprast_bcsd)

    testthat::expect_equal(packbound_stars, "sf")
    testthat::expect_equal(packbound_terra, "terra")
  }
)


testthat::test_that("What package does the input object belong?",
  {
    withr::local_package("stars")
    withr::local_package("terra")
    withr::local_options(list(sf_use_s2 = FALSE))
    bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
    bcsd_stars <- stars::read_stars(bcsd_path)

    nc <- system.file(package = "sf", "shape/nc.shp")
    nc <- sf::read_sf(nc)

    datatype_stars <- datamod(bcsd_stars)
    datatype_sf <- datamod(nc)

    testthat::expect_equal(datatype_stars, "raster")
    testthat::expect_equal(datatype_sf, "vector")

    testthat::expect_error(datamod(list(1, 2)))
  }
)
```

```{r, send_to = "R/preprocessing.R"}
#' @title Switch spatial data class
#' @family Helper functions
#' @description Convert class between `sf`/`stars`-`terra`
#' @author Insang Song
#' @param input Spat* in terra or sf object.
#' @returns Data converted to the other package class
#' (if sf, terra; if terra, sf)
#' @examples
#' library(sf)
#' library(stars)
#' library(terra)
#' options(sf_use_s2 = FALSE)
#'
#' ## generate a random raster
#' ras_rand <- terra::rast(nrow = 30, ncol = 30)
#' terra::values(ras_rand) <- runif(900)
#' stars_rand <- dep_switch(ras_rand)
#' stars_rand
#' # should return stars object
#'
#' vec_rand <- terra::spatSample(ras_rand, size = 10L, as.points = TRUE)
#' sf_rand <- dep_switch(vec_rand)
#' sf_rand
#' # should return sf object
#' @importFrom terra vect
#' @importFrom terra rast
#' @importFrom sf st_as_sf
#' @importFrom stars st_as_stars
#' @export
dep_switch <- function(input) {
  if (!any(class(input) %in% c("sf", "stars", "SpatVector", "SpatRaster"))) {
    stop("Input should be one of sf or Spat* object.\n")
  }
  cls_input <- dep_check(input)
  type_input <- datamod(input)

  switched <-
    switch(cls_input,
      sf = switch(type_input,
        vector = terra::vect(input),
        raster = terra::rast(input)
      ),
      terra = switch(type_input,
        vector = sf::st_as_sf(input),
        raster = stars::st_as_stars(input)
      )
    )

  return(switched)
}
```


```{r test-format, send_to = "tests/testthat/test-preprocessing.R"}

testthat::test_that("Format is well converted",
  {
    withr::local_package("stars")
    withr::local_package("terra")
    withr::local_options(list(sf_use_s2 = FALSE))

    # starts from sf/stars
    bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
    bcsd_stars <- stars::read_stars(bcsd_path)
    nc <- system.file(package = "sf", "shape/nc.shp")
    nc <- sf::read_sf(nc)

    stars_bcsd_tr <- dep_switch(bcsd_stars)
    sf_nc_tr <- dep_switch(nc)

    testthat::expect_equal(dep_check(stars_bcsd_tr), "terra")
    testthat::expect_equal(dep_check(sf_nc_tr), "terra")

    stars_bcsd_trb <- dep_switch(stars_bcsd_tr)
    sf_nc_trb <- dep_switch(sf_nc_tr)

    testthat::expect_equal(dep_check(stars_bcsd_trb), "sf")
    testthat::expect_equal(dep_check(sf_nc_trb), "sf")

    testthat::expect_error(dep_check(list(1, 2)))
    testthat::expect_error(dep_check(matrix(c(1, 2), nrow = 2, byrow = TRUE)))
  }
)


```

```{r, send_to = "R/check.R"}
#' @title Check coordinate system then reproject
#' @family Helper functions
#' @description The input is checked whether its coordinate system is
#'  present. If not, it is reprojected to the CRS specified in
#' \code{crs_standard}.
#' @param input Input object one of sf or terra::Spat* object
#' @param crs_standard character(1). A standard definition of
#'  coordinate reference system. Default is `"EPSG:4326"`
#'  Consult [epsg.io](https://epsg.io) for details of other CRS.
#' @note This function works well with EPSG codes.
#' @returns A (reprojected) `sf` or `SpatVector` object.
#' @author Insang Song
#' @examples
#' library(sf)
#' library(terra)
#' options(sf_use_s2 = FALSE)
#'
#' base_crs <- "EPSG:5070"
#' nc_path <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc_sf <- sf::st_read(nc_path)
#' reproject_std(nc_sf, base_crs)
#'
#' nc_vect <- terra::vect(nc_sf)
#' reproject_std(nc_vect, base_crs)
#' @importFrom sf st_crs
#' @importFrom sf st_transform
#' @importFrom terra crs
#' @importFrom terra project
#' @export
reproject_std <-
  function(
    input,
    crs_standard = "EPSG:4326"
  ) {

    bound_package <- dep_check(input)
    input_crs <- switch(
      bound_package,
      sf = sf::st_crs(input)$epsg,
      terra = terra::crs(input, describe = TRUE)$code
    )
    standard_crs <- switch(
      bound_package,
      sf = sf::st_crs(crs_standard)$epsg,
      terra = terra::crs(crs_standard, describe = TRUE)$code
    )
    if (input_crs == standard_crs) {
      return(input)
    }
    input_transformed <- switch(
      bound_package,
      sf = sf::st_transform(input, sf::st_crs(crs_standard)),
      terra = terra::project(x = input, y = crs_standard)
    )
    return(input_transformed)
}
```


```{r test-crs-align, eval = FALSE, send_to = "tests/testthat/test-check.R"}
testthat::test_that("CRS is transformed when it is not standard", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)
  nc <- sf::st_transform(nc, "EPSG:5070")
  nctr <- terra::vect(nc)
  terra::crs(nctr) <- "EPSG:5070"
  ncna <- nc
  sf::st_crs(ncna) <- NA
  ncnatr <- terra::vect(ncna)

  # testthat::expect_error(reproject_std(nc, 4326))
  # testthat::expect_error(reproject_std(ncna, crs_standard = "EPSG:4326"))
  # testthat::expect_error(reproject_std(ncnatr, "EPSG:4326"))

  testthat::expect_no_error(reproject_std(nc, crs_standard = "EPSG:4326"))
  testthat::expect_no_error(reproject_std(nc, crs_standard = "EPSG:5070"))
  testthat::expect_no_error(reproject_std(nctr, crs_standard = "EPSG:4326"))
  testthat::expect_no_error(reproject_std(nctr, crs_standard = "EPSG:5070"))

  nctr_align <- reproject_std(nctr, "EPSG:4326")
  nc_align <- reproject_std(nc, "EPSG:4326")

  testthat::expect_s3_class(nc_align, "sf")
  testthat::expect_s4_class(nctr_align, "SpatVector")

  nc_align_epsg <- sf::st_crs(nc_align)$epsg
  nctr_align_epsg <- terra::crs(nctr_align, describe = TRUE)$code

  testthat::expect_equal(nc_align_epsg, 4326)
  testthat::expect_equal(nctr_align_epsg, "4326")

  terra::crs(ncnatr) <- NULL
  # error case
  testthat::expect_error(reproject_std(ncnatr, "EPSG:4326"))

})

```


```{r, send_to = "R/check.R"}
#' Validate and repair input vector data
#' @family Helper functions
#' @description It tries repairing input vector data.
#' Vector validity violation usually appears in polygon data with
#' self-crossing or
#' hole orders. This function will pass the input_vector object to
#' [`sf::st_make_valid`] (if input_vector is sf) or
#' [`terra::makeValid`] (if input_vector is SpatVector).
#' May take some time depending on the geometry complexity.
#' @author Insang Song
#' @param input_vector One of sf or vect class. Target points of computation.
#' @returns A repaired `sf` or `SpatVector` object depending on
#' the class of input_vector.
#' @note This function works with GEOS (>=3.8).
#' @examples
#' \dontrun{
#' library(terra)
#' library(sf)
#' ncpath <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc <- terra::vect(ncpath)
#'
#' nc_valid <- vect_valid_repair(nc)
#' }
#' @importFrom terra makeValid
#' @importFrom sf st_make_valid
#' @export
vect_valid_repair <- function(input_vector) {
  detected <- dep_check(input_vector)

  validated <- switch(detected,
    terra = terra::makeValid(input_vector),
    sf = sf::st_make_valid(input_vector)
  )

  return(validated)
}

```


```{r test-validate, eval = FALSE, send_to = "tests/testthat/test-check.R"}
testthat::test_that("vector validity check is cleared", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)

  testthat::expect_no_error(vect_valid_repair(nc))

  nct <- terra::vect(nc)
  testthat::expect_no_error(vect_valid_repair(nct))
})

```



```{r, send_to = "R/preprocessing.R"}
#' Setting the clipping extent
#' @family Helper functions
#' @description Return clipping extent with buffer radius.
#'  It assumes the input CRS is projected and linear unit is meters.
#' @author Insang Song
#' @param pnts One of sf or SpatVector object. Target points of computation.
#' @param radius numeric(1). Buffer radius. It is assumed to be in meters
#' @returns A terra::ext or sfc_POLYGON object of the computation extent.
#' @examples
#' library(sf)
#' library(terra)
#' options(sf_use_s2 = FALSE)
#'
#' nc_path <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc_sf <- sf::st_read(nc_path)
#' nc_sf <- sf::st_transform(nc_sf, "EPSG:5070")
#' get_clip_ext(nc_sf, 2.5e4)
#' nc_vect <- terra::vect(nc_sf)
#' get_clip_ext(nc_vect, 2.5e4)
#' @importFrom terra ext
#' @importFrom sf st_bbox
#' @importFrom sf st_as_sfc
#' @export
get_clip_ext <- function(
  pnts,
  radius
) {
  detected <- dep_check(pnts)
  if (detected == "terra") {
    ext_input <- terra::ext(pnts)
    # Note that `+` operation on
    # terra::ext output accounts for the operand as it is.
    ext_input <- ext_input + (1.1 * radius)
  }
  if (detected == "sf") {
    ext_input <- sf::st_bbox(pnts)
    # Note that `+` operation on st_bbox output
    # simply adds the number; we add a vector here.
    ext_input <- ext_input + ((1.1 * c(-1, -1, 1, 1) * radius))
    ext_input <- sf::st_as_sfc(ext_input)
  }
  return(ext_input)
}
```


```{r test-clip, send_to = "tests/testthat/test-preprocessing.R"}
testthat::test_that("Clip extent is set properly", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  ncpath <- system.file("shape/nc.shp", package = "sf")
  suppressWarnings({
    nc <- sf::read_sf(ncpath) |>
      sf::st_transform("EPSG:5070") |>
      sf::st_centroid()
  })

  radius <- 1e4L

  (nc_ext_sf <- get_clip_ext(nc, radius))

  nct <- terra::vect(nc)
  (nc_ext_terra <- get_clip_ext(nct, radius))

  (proper_xmin <- sf::st_bbox(nc)[1] - (1.1 * radius))

  testthat::expect_s3_class(nc_ext_sf, "sfc")
  testthat::expect_s4_class(nc_ext_terra, "SpatExtent")

  nc_ext_sf_1 <- sf::st_bbox(nc_ext_sf)[1]
  nc_ext_terra_1 <- nc_ext_terra[1]

  testthat::expect_equal(nc_ext_sf_1, proper_xmin)
  testthat::expect_equal(nc_ext_terra_1, proper_xmin)

})

```


```{r, send_to = "R/processing.R"}
#' Clip to the buffered extent of input vector
#' @family Helper functions
#' @description Clip input vector by
#'  the expected maximum extent of computation.
#' @author Insang Song
#' @param pnts `sf` or `SpatVector` object
#' @param radius `numeric(1)`. Circular buffer radius.
#'  this value will be automatically multiplied by 1.1
#' @param target_input `sf` or `SpatVector` object to be clipped
#' @returns A clipped `sf` or `SpatVector` object.
#' @examples
#' library(sf)
#' library(stars)
#' library(terra)
#' options(sf_use_s2 = FALSE)
#'
#' bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
#' bcsd <- stars::read_stars(bcsd_path)
#' bcsd <- sf::st_as_sf(bcsd)
#' bcsd_rpnt <- sf::st_as_sf(sf::st_sample(bcsd, 4L))
#' bcsd_rpntm <- sf::st_as_sf(sf::st_sample(bcsd, 1000L))
#' clip_vec_ext(bcsd_rpntm, 1000, bcsd_rpnt)
#' @importFrom sf st_intersection
#' @importFrom terra intersect
#' @export
clip_vec_ext <- function(
  pnts,
  radius,
  target_input
) {
  if (any(sapply(list(pnts, radius, target_input), is.null))) {
    stop("One or more required arguments are NULL. Please check.\n")
  }
  detected_pnts <- dep_check(pnts)
  detected_target <- dep_check(target_input)

  if (detected_pnts != detected_target) {
    warning("Inputs are not the same class.\n")
    target_input <- dep_switch(target_input)
  }

  ext_input <- get_clip_ext(pnts, radius)
  cat("Clip target features with the input feature extent...\n")
  if (detected_pnts == "sf") {
    cae <- ext_input |>
      sf::st_intersection(x = target_input)
  }
  if (detected_pnts == "terra") {
    cae <- terra::intersect(target_input, ext_input)
  }

  return(cae)
}
```

```{r test-clip-extent-vector, eval = FALSE, send_to = "tests/testthat/test-processing.R"}
testthat::test_that("Vector inputs are clipped by clip_vec_ext", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  ncpath <- system.file("extdata/nc_hierarchy.gpkg", package = "chopin")
  nccnty <- terra::vect(
    ncpath, layer = "county",
    query = "SELECT * FROM county WHERE GEOID IN (37063, 37183)"
  )
  nctrct <- terra::vect(ncpath, layer = "tracts")

  ncp <- readRDS(system.file("extdata/nc_random_point.rds", package = "chopin"))
  ncp <- sf::st_transform(ncp, "EPSG:5070")
  ncpt <- terra::vect(ncp)

  ncpt <- ncpt[nccnty, ]

  # terra-terra
  testthat::expect_no_error(
    suppressWarnings(
      cl_terra <-
        clip_vec_ext(
          pnts = ncpt,
          radius = 3e4L,
          target_input = nctrct
        )
    )
  )
  testthat::expect_s4_class(cl_terra, "SpatVector")

  # sf-sf
  ncp <- sf::st_as_sf(ncpt)
  nccntysf <- sf::st_as_sf(nccnty)
  nctrct <- sf::st_as_sf(nctrct)
  testthat::expect_no_error(
    suppressWarnings(
      cl_sf <-
        clip_vec_ext(
          pnts = ncp,
          radius = 3e4L,
          target_input = nctrct
        )
    )
  )
  testthat::expect_s3_class(cl_sf, "sf")

  # sf-terra
  testthat::expect_no_error(
    suppressWarnings(
      clip_vec_ext(
        pnts = ncpt,
        radius = 3e4L,
        target_input = sf::st_as_sf(nctrct)
      )
    )
  )

  testthat::expect_error(
    clip_vec_ext(
      pnts = NULL, radius = 3e4L, target_input = nctrct
    )
  )

})

```

```{r, send_to = "R/processing.R"}
#' @title Clip input raster with a buffered vector extent.
#' @family Helper functions
#' @description Clip input raster by the expected maximum extent of
#' computation.
#' @param pnts `sf` or `SpatVector` object
#' @param radius numeric(1). buffer radius.
#' This value will be automatically multiplied by 1.25
#' @param ras `SpatRaster` object to be clipped
#' @param nqsegs `integer(1)`. the number of points per a quarter circle
#' @author Insang Song
#' @examples
#' library(terra)
#'
#' ras_rand <- terra::rast(nrow = 20, ncol = 20)
#' terra::values(ras_rand) <- runif(400L)
#' ras_rand_p <-
#'   data.frame(
#'     x = c(3, 5, 3.2, 8),
#'     y = c(12, 10, 15, 12),
#'     z = c(0, 1, 2, 3)
#'   )
#' ras_rand_p <- terra::vect(ras_rand_p, geom = c("x", "y"))
#' clip_ras_ext(ras_rand_p, 1.5, ras_rand)
#' @importFrom terra vect
#' @importFrom terra crop
#' @export
clip_ras_ext <- function(
  pnts = NULL,
  radius = NULL,
  ras = NULL,
  nqsegs = 180L
) {
  if (any(sapply(list(pnts, radius, ras), is.null))) {
    stop("Any of required arguments are NULL. Please check.\n")
  }
  ext_input <- get_clip_ext(pnts, radius) |>
    terra::vect()

  cae <- terra::crop(ras, ext_input, snap = "out")
  return(cae)
}
```


```{r test-clip-extent, eval=F, send_to = "tests/testthat/test-processing.R"}
testthat::test_that("Clip by extent works without errors", {
  withr::local_package("sf")
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  # starts from sf/stars
  ncelev <-
    terra::unwrap(
      readRDS(
        system.file("extdata/nc_srtm15_otm.rds", package = "chopin")
      )
    )
  terra::crs(ncelev) <- "EPSG:5070"
  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)
  ncp <-
    readRDS(
      system.file("extdata/nc_random_point.rds", package = "chopin")
    )
  ncp_terra <- terra::vect(ncp)

  testthat::expect_no_error(clip_ras_ext(ncp, 30000L, ncelev))
  testthat::expect_no_error(clip_ras_ext(ncp_terra, 30000L, ncelev))
  testthat::expect_error(clip_ras_ext(ncp_terra, NULL, ncelev))
})



```

```{r, include=FALSE, eval=FALSE}
#
#
#
#' Quick call for SpatRaster with a window
#' @family Helper functions
#' @param rasterpath character(1). Path to the raster file.
#' @param win Named integer vector (4) or terra::ext() results.
#' @returns SpatRaster object.
#' @author Insang Song
#' @examples
#' library(terra)
#' bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
#' ext_small <- terra::ext(
#'   c(xmin = -80, xmax = -76, ymin = 35, ymax = 36)
#' )
#' rast_short(bcsd_path, ext_small)
#' @importFrom methods is
#' @importFrom terra rast
#' @export
# rast_short <- function(rasterpath = NULL, win = NULL) {
#   if (!(all(is.numeric(win), !is.null(attr(win, "names")), length(win) == 4) ||
#           methods::is(win, "SpatExtent"))) {
#     stop(
#       "Argument win should be one of named numeric vector or SpatExtent object.
#       \n"
#     )
#   }
#   rast_sub <- terra::rast(rasterpath, win = win)
#   return(rast_sub)
# }

```


```{r test-rasterbound, include=FALSE, eval=FALSE}
#
#
# testthat::test_that("Raster is read properly with a window.", {
#   withr::local_package("stars")
#   withr::local_package("terra")
#   withr::local_options(list(sf_use_s2 = FALSE))
#   bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")

#   ext_numeric <- c(-84, -82, 34, 36) # unnamed
#   testthat::expect_error(terra::rast(x = bcsd_path, win = ext_numeric[1:3]))
#   testthat::expect_no_error(terra::rast(x = bcsd_path, win = ext_numeric))

#   names(ext_numeric) <- c("xmin", "xmax", "ymin", "ymax")
#   rastshort_num <- terra::rast(x = bcsd_path, win = ext_numeric)
#   testthat::expect_s4_class(rastshort_num, "SpatRaster")

#   ext_terra <- terra::ext(ext_numeric)
#   rastshort_terra <- terra::rast(x = bcsd_path, win = ext_terra)
#   testthat::expect_s4_class(rastshort_terra, "SpatRaster")

# })


```


```{r, include = FALSE, eval = FALSE}
# Estimate computational demands from inputs (to be written)
#' @param inputs character vector of file paths
#' @param nx integer(1).
#' @param ny integer(1).
#' @param padding numeric(1). Extrusion factor
#' @author Insang Song
#' @export
estimate_demands <- function(
  inputs,
  nx, ny,
  padding
) {

  setMethod(
    "estimate_flow",
    "SpatRaster",
    f)
  ## cpu
  lobstr::cst()
  ## memory
  ## estimate maximum coverage
  ## clipped data size
  ## total distributed memory
  ## return a list of total demands
  ## print summary of results
}

nc_valid <- vect_valid_repair(nc)
```


```{r gridding-suite, send_to = "R/gridding.R"}
#' Get a set of computational grids
#' @family Parallelization
#' @param input sf or Spat* object.
#' @param mode character(1). Mode of region construction.
#'  One of
#' * `"grid"` (simple grid regardless of the number of features in each grid)
#' * `"density"` (clustering-based varying grids),
#' * `"grid_advanced"` (merging adjacent grids with
#'  smaller number of features than `grid_min_features`).
#'  The argument `grid_min_features` should be specified.
#' * `"grid_quantile"` (x and y quantiles): an argument `quantiles` should
#' be specified.
#' @param nx integer(1). The number of grids along x-axis.
#' @param ny integer(1). The number of grids along y-axis.
#' @param grid_min_features integer(1). A threshold to merging adjacent grids
#' @param padding numeric(1). A extrusion factor to make buffer to
#'  clip actual datasets. Depending on the length unit of the CRS of input.
# nolint start
#' @param unit character(1). The length unit for padding (optional).
#'  units::set_units is used for padding when sf object is used.
#'  See [units package vignette (web)](https://cran.r-project.org/web/packages/units/vignettes/measurement_units_in_R.html)
#'  for the list of acceptable unit forms.
#' @param quantiles numeric. Quantiles for `grid_quantile` mode.
# nolint end
#' @param ... arguments passed to the internal function
#' @returns A list of two,
#'  * \code{original}: exhaustive and non-overlapping
#'  grid polygons in the class of input
#'  * \code{padded}: a square buffer of each polygon in
#'  \code{original}. Used for computation.
#' @description Using input points, the bounding box is split to
#'  the predefined numbers of columns and rows.
#'  Each grid will be buffered by the radius.
#' @seealso [par_cut_coords], [par_merge_grid]
#' @author Insang Song
#' @examples
#' # data
#' library(sf)
#' ncpath <- system.file("shape/nc.shp", package = "sf")
#' nc <- read_sf(ncpath)
#' nc <- st_transform(nc, "EPSG:5070")
#' # run: nx and ny should strictly be integers
#' # In the example below, nx is 12L, not 12.
#' nc_comp_region <-
#'   par_make_gridset(
#'     nc,
#'     mode = "grid",
#'     nx = 12L, ny = 8L,
#'     padding = 10000)
#' par(mfcol = c(1, 2))
#' plot(nc_comp_region$original)
#' plot(nc_comp_region$padded)
#' @importFrom sf st_crs
#' @importFrom sf st_set_crs
#' @importFrom terra crs
#' @importFrom terra set.crs
#' @importFrom terra buffer
#' @export
par_make_gridset <-
  function(
      input,
      mode = c("grid", "grid_advanced", "density", "grid_quantile"),
      nx = 10L,
      ny = 10L,
      grid_min_features = 30L,
      padding = NULL,
      unit = NULL,
      quantiles = NULL,
      ...) {
    mode <- match.arg(mode)

    if (!all(
      is.integer(nx),
      is.integer(ny)
    )
    ) {
      stop("nx, ny must be integer.\n")
    }
    if (!is.numeric(padding)) {
      message("padding should be numeric.
We try converting padding to numeric...\n")
      padding <- as.numeric(padding)
      if (any(inherits(padding, "try-error"), is.na(padding))) {
        stop("padding is not convertible to numeric or converted to NA.\n")
      }
    }

    # valid unit compatible with units::set_units?
    grid_reg <-
      switch(mode,
        grid = par_make_grid(points_in = input, ncutsx = nx, ncutsy = ny),
        grid_advanced =
        par_merge_grid(
          points_in = input,
          par_make_grid(input, nx, ny),
          grid_min_features = grid_min_features
        ),
        grid_quantile = par_cut_coords(
          x = input,
          y = NULL,
          quantiles = quantiles
        ),
        density = simpleError("density method is under development.\n")
      )

    # type_grid_reg <- dep_check(grid_reg)
    if (dep_check(grid_reg) == "sf") {
      grid_reg <- sf::st_set_crs(grid_reg, sf::st_crs(input))
      grid_reg_conv <- dep_switch(grid_reg)
    } else {
      grid_reg <- terra::set.crs(grid_reg, terra::crs(input))
      grid_reg_conv <- grid_reg
    }

    grid_reg_pad <-
      # switch(type_grid_reg,
      #        sf =
      #        sf::st_buffer(grid_reg,
      #                      dist = padding,
      #                      endCapStyle = "SQUARE",
      #                      joinStyle = "MITRE"),
            #  terra =
      terra::buffer(
        grid_reg_conv,
        width = padding,
        capstyle = "square",
        joinstyle = "mitre"
      )
    if (dep_check(grid_reg) != dep_check(grid_reg_pad)) {
      grid_reg_pad <- dep_switch(grid_reg_pad)
    }
    grid_results <-
      list(original = grid_reg,
           padded = grid_reg_pad)
    return(grid_results)

  }

#' @title Generate grid polygons
#' @family Parallelization
#' @description Returns a sf object that includes x- and y- index
#' by using two inputs ncutsx and ncutsy, which are x- and
#' y-directional splits, respectively.
#' @param points_in `sf` or `SpatVector` object. Target points of computation.
#' @param ncutsx integer(1). The number of splits along x-axis.
#' @param ncutsy integer(1). The number of splits along y-axis.
#' @returns A `sf` or `SpatVector` object of computation grids with
#' unique grid id (CGRIDID).
#' @note Grids are generated based on the extent of `points_in` first,
#' then exhaustive grids will be filtered by the intersection between
#' these and `points_in`. Thus, the number of generated grids may be
#' smaller than `ncutsx * ncutsy`.
#' @author Insang Song
#' @examples
#' library(sf)
#' library(terra)
#' options(sf_use_s2 = FALSE)
#'
#' nc_path <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc <- terra::vect(nc_path)
#' nc_rp <- terra::spatSample(nc, 1000)
#' nc_gr <- par_make_grid(nc_rp, 10L, 6L)
#'
#' plot(nc_rp)
#' plot(nc_gr, add = TRUE)
#' @importFrom terra rast
#' @importFrom terra as.polygons
#' @importFrom sf st_as_sf
#' @importFrom sf st_make_grid
#' @export
par_make_grid <-
  function(
    points_in = NULL,
    ncutsx = NULL,
    ncutsy = NULL
  ) {
    package_detected <- dep_check(points_in)

    grid_out <-
      switch(package_detected,
        sf = sf::st_make_grid(points_in, n = c(ncutsx, ncutsy)) |>
          as.data.frame() |>
          sf::st_as_sf(),
        terra = terra::rast(points_in, nrows = ncutsy, ncols = ncutsx) |>
          terra::as.polygons()
      )
    # grid select
    grid_out <- grid_out[points_in, ]

    grid_out$CGRIDID <- seq(1, nrow(x = grid_out))
    return(grid_out)
  }


#' Quantile definition
#' @family Helper functions
#' @param steps integer(1). The number of quantiles.
#' @returns numeric vector of quantiles.
#' @examples
#' par_def_q(5L)
#' @export
par_def_q <- function(steps = 4L) {
  if (steps < 2L) {
    stop("steps should be greater than 1.")
  }
  quantiles <- seq(0, 1, length.out = steps + 1)
  return(quantiles)
}


#' @title Partition coordinates into quantile polygons
#' @note This function is only for two-dimensional points.
#' @family Parallelization
#' @param x numeric/sf/SpatVector. x-coordinates (if numeric).
#' @param y numeric. y-coordinates.
#' @param quantiles numeric vector. Quantiles.
#' @returns A `SpatVector` object with field `CGRIDID`.
#' @examples
#' library(terra)
#' random_points <-
#'   data.frame(x = runif(1000, 0, 100), y = runif(1000, 0, 100))
#' quantiles <- par_def_q(4L)
#' qpoly <- par_cut_coords(random_points$x, random_points$y, quantiles)
#' clustered_points <-
#'   data.frame(x = rgamma(1000, 1, 1), y = rgamma(1000, 4, 1))
#' qpoly_c <- par_cut_coords(clustered_points$x, clustered_points$y, quantiles)
#' par(mfcol = c(1, 2))
#' plot(qpoly)
#' plot(qpoly_c)
#' par(mfcol = c(1, 1))
#' cvect <- terra::vect(clustered_points, geom = c("x", "y"))
#' plot(cvect)
#' plot(qpoly_c, add = TRUE, col = "transparent", border = "red")
#' qcv <- intersect(cvect, qpoly_c)
#' table(qcv$CGRIDID)
#' sum(table(qcv$CGRIDID)) # should be 1000
#' @importFrom methods is
#' @importFrom sf st_coordinates
#' @importFrom terra crds
#' @importFrom terra ext
#' @importFrom terra as.polygons
#' @importFrom stats setNames
#' @importFrom stats quantile
#' @export
par_cut_coords <- function(x = NULL, y = NULL, quantiles) {
  if (any(methods::is(x, "sf"), methods::is(x, "SpatVector"))) {
    coord <- if (methods::is(x, "sf")) sf::st_coordinates else terra::crds
    detectgeom <-
      if (methods::is(x, "sf")) sf::st_geometry_type else terra::geomtype
    center <- if (methods::is(x, "sf")) sf::st_centroid else terra::centroids
    if (any(grepl("polygon", tolower(unique(detectgeom(x)))))) {
      x <- center(x)
    }

    invect <- coord(x)
    x <- invect[, 1]
    y <- invect[, 2]
  }
  if (!all.equal(length(x), length(y))) {
    stop("x and y should have the same length.")
  }
  x_quantiles <- stats::quantile(x, probs = quantiles)
  y_quantiles <- stats::quantile(y, probs = quantiles)

  # these lines are rounding quantiles between
  # the minimum and the maximum (exclusive) to the nearest 4th decimal place
  x_quantiles[-c(1, length(x_quantiles))] <-
    sapply(
      x_quantiles[-c(1, length(x_quantiles))],
      function(x) round(x, 4L - ceiling(log10(abs(x) - as.integer(x))))
    )
  y_quantiles[-c(1, length(y_quantiles))] <-
    sapply(
      y_quantiles[-c(1, length(y_quantiles))],
      function(x) round(x, 4L - ceiling(log10(abs(x) - as.integer(x))))
    )

  xy_quantiles <- expand.grid(
    x = x_quantiles,
    y = y_quantiles
  )

  # leveraging the auto-sorting factor levels and
  # ll-rr combinations for terra::ext, then convert to polygons
  xy_quantiles$xindx <- as.integer(factor(xy_quantiles$x))
  xy_quantiles$yindx <- as.integer(factor(xy_quantiles$y))
  xy_quantiles_next <- xy_quantiles
  xy_quantiles$xurindx <- xy_quantiles$xindx + 1
  xy_quantiles$yurindx <- xy_quantiles$yindx + 1
  xy_quantiles_next <-
    stats::setNames(xy_quantiles_next, c("xur", "yur", "xurindx", "yurindx"))
  xy_quantiles <-
    merge(xy_quantiles, xy_quantiles_next, by = c("xurindx", "yurindx"))
  exts <- mapply(
    function(xur, yur, x, y) {
      terra::as.polygons(terra::ext(c(x, xur, y, yur)))
    },
    xy_quantiles$xur,
    xy_quantiles$yur,
    xy_quantiles$x,
    xy_quantiles$y,
    SIMPLIFY = TRUE
  )
  xy_poly <- Reduce(rbind, exts)
  xy_poly$CGRIDID <- seq(1, nrow(xy_poly))

  return(xy_poly)
}


#' @title Merge adjacent grid polygons with given rules
#' @family Parallelization
#' @description Merge boundary-sharing (in "Rook" contiguity) grids with
#'  fewer target features than the threshold.
#'  This function strongly assumes that the input
#'  is returned from the par_make_grid,
#'  which has `"CGRIDID"` as the unique id field.
#' @author Insang Song
#' @param points_in `sf` or `SpatVector` object. Target points of computation.
#' @param grid_in `sf` or `SpatVector` object.
#' The grid generated by [`par_make_grid`].
#' @param grid_min_features integer(1). Threshold to merge adjacent grids.
#' @returns A `sf` or `SpatVector` object of computation grids.
#' @examples
#' \dontrun{
#' library(sf)
#' library(igraph)
#' ligrary(dplyr)
#' dg <- sf::st_as_sfc(st_bbox(c(xmin = 0, ymin = 0, xmax = 8e5, ymax = 6e5)))
#' sf::st_crs(dg) <- 5070
#' dgs <- sf::st_as_sf(st_make_grid(dg, n = c(20, 15)))
#' dgs$CGRIDID <- seq(1, nrow(dgs))
#'
#' dg_sample <- sf::st_sample(dg, kappa = 5e-9, mu = 15,
#' scale = 15000, type = "Thomas")
#' sf::st_crs(dg_sample) <- sf::st_crs(dg)
#' dg_merged <- par_merge_grid(sf::st_as_sf(dg_sample), dgs, 100)
#' plot(dg_merged$geometry)
#' #### NOT RUN ####
#' }
#' @references
#' Polsby, D. D., & Popper, F. J. (1991). The Third Criterion: Compactness as a Procedural Safeguard Against Partisan Gerrymandering. _Yale Law & Policy Review_, 9(2), 301â€“353. [Link](http://hdl.handle.net/20.500.13051/17448)
#' @importFrom dplyr group_by
#' @importFrom dplyr summarize
#' @importFrom dplyr ungroup
#' @importFrom dplyr n
#' @importFrom sf st_relate
#' @importFrom sf st_length
#' @importFrom sf st_cast
#' @importFrom sf st_intersects
#' @importFrom sf st_as_sf
#' @importFrom sf st_area
#' @importFrom rlang sym
#' @importFrom igraph graph_from_edgelist
#' @importFrom igraph mst
#' @importFrom igraph components
#' @importFrom utils combn
#' @export
par_merge_grid <-
  function(
    points_in = NULL,
    grid_in = NULL,
    grid_min_features = NULL
  ) {
    package_detected <- dep_check(points_in)
    if (package_detected == "terra") {
      points_in <- sf::st_as_sf(points_in)
      grid_in <- sf::st_as_sf(grid_in)
    }

    n_points_in_grid <- lengths(sf::st_intersects(grid_in, points_in))
    grid_self <- sf::st_relate(grid_in, grid_in, pattern = "2********")
    grid_rook <- sf::st_relate(grid_in, grid_in, pattern = "F***1****")
    grid_rooks <- mapply(c, grid_self, grid_rook, SIMPLIFY = FALSE)
    grid_lt_threshold <- (n_points_in_grid < grid_min_features)

    # does the number of points per grid exceed minimum threshold?
    if (sum(grid_lt_threshold) < 2) {
      stop(
        sprintf(
          "Threshold is too low. Please try higher threshold.\n
        min # points in grids: %d, your threshold: %d\n",
          min(n_points_in_grid), grid_min_features
        )
      )
    }
    grid_lt_threshold <- seq(1, nrow(grid_in))[grid_lt_threshold]

    # This part does not work as expected.
    # Should investigate edge list and actual row index of the grid object;
    identified <- lapply(grid_rooks,
                         function(x) sort(x[which(x %in% grid_lt_threshold)]))
    identified <- identified[grid_lt_threshold]
    identified <- unique(identified)
    identified <- identified[sapply(identified, length) > 1]

    # Minimum spanning tree
    identified_graph <-
      lapply(identified, function(x) t(utils::combn(x, 2))) |>
      Reduce(f = rbind, x = _) |>
      unique() |>
      apply(X = _, 2, as.character) |>
      igraph::graph_from_edgelist(el = _, directed = 0) |>
      igraph::mst() |>
      igraph::components()

    identified_graph_member <- identified_graph$membership

    merge_idx <- as.integer(names(identified_graph_member))
    merge_member <- split(merge_idx, identified_graph_member)
    merge_member_label <-
      unlist(lapply(merge_member, function(x) paste(x, collapse = "_")))
    merge_member_label <- merge_member_label[identified_graph_member]

    # sf object manipulation
    grid_out <- grid_in
    grid_out[["CGRIDID"]][merge_idx] <- merge_member_label

    grid_out <- grid_out |>
      dplyr::group_by(!!rlang::sym("CGRIDID")) |>
      dplyr::summarize(n_merged = dplyr::n()) |>
      dplyr::ungroup()

    ## Polsby-Popper test for shape compactness
    par_merge_gridd <- grid_out[which(grid_out$n_merged > 1), ]
    par_merge_gridd_area <- as.numeric(sf::st_area(par_merge_gridd))
    par_merge_gridd_perimeter <-
      as.numeric(sf::st_length(sf::st_cast(par_merge_gridd, "LINESTRING")))
    par_merge_gridd_pptest <-
      (4 * pi * par_merge_gridd_area) / (par_merge_gridd_perimeter ^ 2)

    # pptest value is bounded [0,1];
    # 0.3 threshold is groundless at this moment,
    # possibly will make it defined by users.
    if (max(unique(identified_graph_member)) > floor(0.1 * nrow(grid_in)) ||
          any(par_merge_gridd_pptest < 0.3)) {
      message("The reduced computational regions have too complex shapes.
      Consider increasing thresholds or using the original grids.\n")
    }

    return(grid_out)
}

```

```{r test-quantiles, eval = FALSE, send_to = "tests/testthat/test-gridding.R"}
testthat::test_that("Quantile cut tests", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  rv <- terra::vect(matrix(rpois(100, 8), ncol = 2))
  rs <- sf::st_as_sf(rv)

  testthat::expect_no_error(
    par_cut_coords(rv, NULL, par_def_q(4L))
  )
  testthat::expect_no_error(
    par_cut_coords(rs, NULL, par_def_q(4L))
  )

  # numeric cases
  randpoints <- data.frame(
    x = runif(1000, 0, 100),
    y = runif(1000, 0, 100)
  )
  testthat::expect_no_error(
    quantiles <- par_def_q(4L)
  )
  testthat::expect_equal(length(quantiles), 5)
  testthat::expect_error(
    par_def_q(1L)
  )

  testthat::expect_no_error(
    par_cut_coords(randpoints$x, randpoints$y, quantiles)
  )
  testthat::expect_error(
    par_cut_coords(randpoints$x, randpoints$y[seq(1, 100)], quantiles)
  )

  testthat::expect_equal(
    par_cut_coords(randpoints$x, randpoints$y, quantiles) |>
      nrow(),
    16
  )

  testthat::expect_error(
    par_cut_coords(randpoints$x, c(1, 0, 4), quantiles)
  )

  # polygon case
  ncpath <- system.file("gpkg/nc.gpkg", package = "sf")
  nc <- sf::st_read(ncpath)
  testthat::expect_warning(
    testthat::expect_warning(
      par_cut_coords(nc, NULL, par_def_q(3L))
    )
  )

})


```



```{r grid-internal, include = F, eval = F}
par_make_grid_sf <- function(points_in, ncutsx, ncutsy) {
  grid1 <- sf::st_make_grid(points_in, n = c(ncutsx, ncutsy)) |>
    as.data.frame() |>
    sf::st_as_sf()
  grid1 <- grid1[points_in, ]
  return(grid1)
}
par_make_grid_terra <- function(points_in, ncutsx, ncutsy) {
  grid1 <- terra::rast(points_in, nrows = ncutsy, ncols = ncutsx)
  grid1 <- terra::as.polygons(grid1)
  grid1 <- grid1[points_in, ]
  return(grid1)
}
```

```{r test-compregion, send_to = "tests/testthat/test-gridding.R"}
testthat::test_that("Grid split is well done.", {
  withr::local_package("sf")
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  # starts from sf/stars
  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)
  nc <- sf::st_transform(nc, "EPSG:5070")

  testthat::expect_no_error(
    par_make_gridset(nc, mode = "grid", padding = 3e4L)
  )
  ncgrid <- par_make_gridset(nc, mode = "grid", padding = 3e4L)
  testthat::expect_s3_class(ncgrid$original, "sf")

  nctr <- terra::vect(nc)
  testthat::expect_no_error(
    par_make_gridset(nctr, mode = "grid", padding = 3e4L)
  )
  ncgridtr <- par_make_gridset(nctr, mode = "grid", padding = 3e4L)
  testthat::expect_s4_class(ncgridtr$original, "SpatVector")

  testthat::expect_error(
    par_make_gridset(nctr, mode = "grid", nx = 3.6, ny = 10L, padding = 3e4L)
  )
  testthat::expect_error(
    suppressWarnings(
      par_make_gridset(nctr, mode = "grid", nx = 4L, ny = 10L, padding = "july")
    )
  )

  ncp <- readRDS(system.file("extdata/nc_random_point.rds", package = "chopin"))
  ncp <- sf::st_transform(ncp, "EPSG:5070")
  ncrp <- sf::st_as_sf(sf::st_sample(nc, 1000L))

  # Points
  testthat::expect_warning(
    par_make_gridset(
      ncp,
      mode = "grid_advanced",
      padding = 3e4L,
      grid_min_features = 20L
    )
  )
  # Points
  testthat::expect_no_error(
    par_make_gridset(
      ncp,
      mode = "grid_quantile",
      padding = 3e4L,
      quantiles = par_def_q(5L)
    )
  )

})

```

```{r test-gridmerge, eval=FALSE, send_to = "tests/testthat/test-gridding.R"}
testthat::test_that("Grid merge is well done.", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_package("igraph")
  withr::local_package("dplyr")
  withr::local_options(list(sf_use_s2 = FALSE))
  withr::local_seed(202403)

  nc <- system.file("shape/nc.shp", package = "sf")
  nc <- sf::read_sf(nc)
  nc <- sf::st_transform(nc, "EPSG:5070")
  nctr <- terra::vect(nc)
  ncp <- readRDS(system.file("extdata/nc_random_point.rds", package = "chopin"))
  ncp <- sf::st_transform(ncp, "EPSG:5070")
  ncrp <- sf::st_as_sf(sf::st_sample(nc, 500L))

  gridded <-
    par_make_gridset(ncrp,
                     mode = "grid",
                     nx = 8L, ny = 5L,
                     padding = 1e4L)
  # suppress warnings for "all sub-geometries for which ..."
  testthat::expect_warning(par_merge_grid(ncrp, gridded$original, 10L))
  testthat::expect_error(par_merge_grid(ncrp, gridded$original, 2L))

  ncptr <- terra::vect(ncrp)
  griddedtr <-
    par_make_gridset(ncptr,
                     mode = "grid",
                     nx = 8L, ny = 5L,
                     padding = 1e4L)
  testthat::expect_warning(par_merge_grid(ncptr, griddedtr$original, 25L))

})

```


```{r, send_to = "R/check.R"}
#' Generate a rectangular polygon from extent
#' @family Helper functions
#' @param extent input extent.
#'  A numeric vector with xmin/xmax/ymin/ymax,
#'  [sf::st_bbox] or [terra::ext] outputs.
#' @param output_class character(1).
#'  Class of the output polygon. One of `"sf"` or `"terra"`
#' @param crs character(1). Coordinate reference system definition.
#' @returns `sf` or `SpatVector` object of a rectangular polygon.
#' @author Insang Song
#' @examples
#' library(sf)
#' library(terra)
#' numext1 <- c(-100, -70, 30, 40)
#' names(numext1) <- c("xmin", "xmax", "ymin", "ymax")
#' ext2poly(numext1, "sf")
#' ext2poly(numext1, "terra")
#' @importFrom sf st_as_sf
#' @importFrom sf st_bbox
#' @importFrom sf st_set_crs
#' @importFrom terra vect
#' @importFrom terra ext
#' @importFrom terra set.crs
#' @export
ext2poly <- function(
    extent = NULL,
    output_class = c("sf", "terra"),
    crs = "EPSG:4326") {
  output_class <- match.arg(output_class)
  if (methods::is(extent, "numeric")) {
    if (is.null(attr(extent, "names"))) {
      stop("Your extent is an unnamed numeric vector.
Please define names xmin/xmax/ymin/ymax explicitly.\n")
    }
    extent <- switch(
      output_class,
      sf = sf::st_bbox(extent),
      terra = terra::ext(extent)
    )
  }

  extent_polygon <- switch(
    output_class,
    sf = sf::st_as_sf(sf::st_as_sfc(extent)),
    terra = terra::vect(extent)
  )

  extent_polygon <- switch(
    output_class,
    sf = sf::st_set_crs(extent_polygon, sf::st_crs(crs)),
    terra = terra::set.crs(extent_polygon, terra::crs(crs))
  )

  return(extent_polygon)

}

```

```{r test-extentpoly, send_to = "tests/testthat/test-check.R"}
testthat::test_that("input extent is converted to a polygon", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  mainland_vec <- c(xmin = -128, xmax = -62, ymin = 25, ymax = 52)
  mainland_box <- ext2poly(mainland_vec, output_class = "sf")
  mainland_box_t <- ext2poly(mainland_vec, output_class = "terra")
  mainland_vec_un <- unname(mainland_vec)

  testthat::expect_s3_class(mainland_box, "sf")
  # terra Spat* objects are s4 class...
  testthat::expect_s4_class(mainland_box_t, "SpatVector")
  # error cases
  testthat::expect_error(
    ext2poly(mainland_vec_un, output_class = "sf")
  )
  testthat::expect_error(
    ext2poly(mainland_vec_un, output_class = "GeoDataFrames")
  )
})

```



```{r, send_to = "R/check.R"}
#' Check if the data extent is inside the reference bounding box
#' @family Helper functions
#' @description One of the most common errors in spatial computation is rooted
#' in the entirely or partly incomparable spatial extents of input datasets.
#' This function returns whether your data is inside the target computational
#' extent.
#' It is assumed that you know and have the exact computational region.
#' This function will return `TRUE` if the reference region
#' completely contains your data's extent and `FALSE` otherwise.
#' @param data_query sf*/stars/SpatVector/SpatRaster object.
#' @param reference sf*/stars/SpatVector/SpatRaster object
#' @returns logical(1). `TRUE` (the queried data extent is completely within
#'  the reference bounding box) or `FALSE`
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' library(sf)
#' ncpath <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc <- sf::st_read(ncpath)
#' nc <- sf::st_transform(nc, "EPSG:4326")
#'
#' refextnum <- c(-100, -60, 20, 40)
#' names(refextnum) <- c("xmin", "xmax", "ymin", "ymax")
#' refext <- ext2poly(refextnum)
#' is_bbox_within_reference(nc, refext)
#' @importFrom sf st_as_sfc
#' @importFrom sf st_crs
#' @importFrom sf st_bbox
#' @importFrom sf st_transform
#' @importFrom sf st_within
#' @export
is_bbox_within_reference <- function(
  data_query = NULL,
  reference = NULL
) {
  reference <- sf::st_as_sfc(sf::st_bbox(reference))
  print(sf::st_crs(reference))

  data_query_bb <-
    sf::st_as_sfc(sf::st_bbox(data_query),
                  crs = sf::st_crs(data_query))
  print(sf::st_crs(data_query_bb))
  query_matched <- sf::st_transform(data_query_bb, sf::st_crs(reference))
  check_result <- as.logical(unlist(sf::st_within(query_matched, reference)))
  return(check_result)
}


```

```{r test-bbox, eval=FALSE, send_to = "tests/testthat/test-check.R"}
testthat::test_that("Check bbox abides.", {
  withr::local_package("sf")
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))

  # starts from sf/stars
  nc <- system.file(package = "sf", "shape/nc.shp")
  nc <- sf::read_sf(nc)
  nc <- sf::st_transform(nc, "EPSG:5070")
  ncp <- readRDS(system.file("extdata/nc_random_point.rds", package = "chopin"))
  ncp <- sf::st_transform(ncp, "EPSG:5070")

  testthat::expect_no_error(is_bbox_within_reference(ncp, nc))
  res <- is_bbox_within_reference(ncp, nc)
  testthat::expect_equal(res, TRUE)

  # error cases
  testthat::expect_no_error(
    is_bbox_within_reference(ncp, sf::st_bbox(nc))
  )
})

```


```{r, send_to = "R/processing.R"}
#' @title Extract summarized values from raster with points and a buffer radius
#' @family Macros for calculation
#' @description For simplicity, it is assumed that the coordinate systems of
#'  the points and the raster are the same.
#' @note
#' When `Sys.setenv("CHOPIN_FORCE_CROP" = "TRUE")` is set, the raster will be
#' cropped to the extent of the polygons (with `snap` = `"out"`).
#' To note, the function is designed to work with the `exactextractr` package.
#' Arguments of `exactextractr::exact_extract` are set as below
#' (default otherwise listed):
#' * `force_df` = `TRUE`
#' * `stack_apply` = `TRUE`
#' * `max_cells_in_memory` = `2e8`
#' * `progress` = `FALSE`
#' @param points `sf`/`SpatVector` object.
#' Coordinates where buffers will be generated.
#' @param surf `SpatRaster` object or file path(s) with extensions
#' that are GDAL-compatible. A raster from which a summary will be calculated
#' @param radius numeric(1). Buffer radius. here we assume circular buffers only
#' @param id character(1). Unique identifier of each point.
#' @param qsegs integer(1). Number of vertices at a quarter of a circle.
#'  Default is `90L`.
#' @param func a function taking a numeric vector argument.
#' @param kernel character(1). Name of a kernel function
#' One of `"uniform"`, `"triweight"`, `"quartic"`, and `"epanechnikov"`
#' @param bandwidth numeric(1). Kernel bandwidth.
#' @param max_cells integer(1). Maximum number of cells in memory.
#' See [`exactextractr::exact_extract`] for more details.
#' @returns a data.frame object with mean value
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' library(terra)
#' rrast <- terra::rast(nrow = 100, ncol = 100)
#' terra::crs(rrast) <- "EPSG:5070"
#' terra::values(rrast) <- rgamma(1e4, 4, 2)
#' rpnt <- terra::spatSample(rrast, 100L, as.points = TRUE)
#' rpnt$pid <- sprintf("id_%03d", seq(1, 100))
#' extract_at_buffer(rpnt, rrast, 4, "pid")
#' @importFrom exactextractr exact_extract
#' @importFrom methods is
#' @importFrom terra ext
#' @importFrom terra crop
#' @importFrom terra buffer
#' @importFrom dplyr group_by
#' @importFrom dplyr summarize
#' @importFrom dplyr all_of
#' @importFrom dplyr across
#' @importFrom dplyr ungroup
#' @export
extract_at_buffer <- function(
  points = NULL,
  surf = NULL,
  radius = NULL,
  id = NULL,
  qsegs = 90L,
  func = "mean",
  kernel = NULL,
  bandwidth = NULL,
  max_cells = 2e7
) {
  # type check
  if (!methods::is(points, "SpatVector")) {
    if (!methods::is(points, "sf")) {
      stop("Check class of the input points.\n")
    }
    points <- terra::vect(points)
  }
  if (!methods::is(surf, "SpatRaster")) {
    surf <- try(terra::rast(surf))
    if (inherits(surf, "try-error")) {
      stop("Check class of the input raster.\n")
    }
  }
  if (!is.numeric(radius)) {
    stop("Check class of the input radius.\n")
  }
  if (!is.character(id)) {
    stop("id should be a character.\n")
  }
  if (!is.numeric(qsegs)) {
    stop("qsegs should be numeric.\n")
  }

  if (!is.null(kernel)) {
    extracted <-
      extract_at_buffer_kernel(
        points = points,
        surf = surf,
        radius = radius,
        id = id,
        func = func,
        qsegs = qsegs,
        kernel = kernel,
        bandwidth = bandwidth,
        max_cells = max_cells
      )
    return(extracted)
  }

  extracted <-
    extract_at_buffer_flat(
      points = points,
      surf = surf,
      radius = radius,
      id = id,
      func = func,
      qsegs = qsegs,
      max_cells = max_cells
    )
  return(extracted)

}

# Subfunction: extract at buffers with uniform weights
#' @rdname extract_at_buffer
#' @export
extract_at_buffer_flat <- function(
  points = NULL,
  surf = NULL,
  radius = NULL,
  id = NULL,
  qsegs = NULL,
  func = "mean",
  kernel = NULL,
  bandwidth = NULL,
  max_cells = 2e7
) {
  # generate buffers
  bufs <- terra::buffer(points, width = radius, quadsegs = qsegs)
  bufs <- reproject_b2r(bufs, surf)
  # crop raster
  if (Sys.getenv("CHOPIN_FORCE_CROP") == "TRUE") {
    bufs_extent <- terra::ext(bufs)
    surf_cropped <- terra::crop(surf, bufs_extent, snap = "out")
  } else {
    surf_cropped <- surf
  }

  # extract raster values
  surf_at_bufs <-
    exactextractr::exact_extract(
      x = surf_cropped,
      y = sf::st_as_sf(bufs),
      fun = func,
      force_df = TRUE,
      stack_apply = TRUE,
      append_cols = id,
      progress = FALSE,
      max_cells_in_memory = max_cells
    )
  return(surf_at_bufs)
}


# Subfunction: extract at buffers with kernel weight
#' @rdname extract_at_buffer
#' @export
extract_at_buffer_kernel <- function(
  points = NULL,
  surf = NULL,
  radius = NULL,
  id = NULL,
  qsegs = NULL,
  func = stats::weighted.mean,
  kernel = NULL,
  bandwidth = NULL,
  max_cells = 2e7
) {
  # generate buffers
  bufs <- terra::buffer(points, width = radius, quadsegs = qsegs)
  bufs <- reproject_b2r(bufs, surf)

  # crop raster
  if (Sys.getenv("CHOPIN_FORCE_CROP") == "TRUE") {
    bufs_extent <- terra::ext(bufs)
    surf_cropped <- terra::crop(surf, bufs_extent, snap = "out")
  } else {
    surf_cropped <- surf
  }

  name_surf_val <-
    ifelse(terra::nlyr(surf_cropped) == 1,
           "value", names(surf_cropped))
  # convert to data.frame
  coords_df <- as.data.frame(points, geom = "XY")
  # apply strict order
  coords_df <-
    coords_df[, grep(sprintf("^(%s|%s|%s)", id, "x", "y"), names(coords_df))]
  names(coords_df)[grep("(x|y)", names(coords_df))] <- c("xorig", "yorig")

  # for linter purpose
  xorig <- NULL
  yorig <- NULL
  x <- NULL
  y <- NULL
  pairdist <- NULL
  w_kernel <- NULL
  coverage_fraction <- NULL

  # extract raster values
  surf_at_bufs <-
    exactextractr::exact_extract(
      x = surf_cropped,
      y = sf::st_as_sf(bufs),
      force_df = TRUE,
      stack_apply = FALSE,
      include_cols = id,
      progress = FALSE,
      include_area = TRUE,
      include_xy = TRUE,
      max_cells_in_memory = max_cells
    )
  # post-processing
  surf_at_bufs <- do.call(rbind, surf_at_bufs)
  surf_at_bufs_summary <-
    surf_at_bufs |>
    dplyr::left_join(coords_df, by = id) |>
    # averaging with kernel weights
    dplyr::mutate(
      pairdist = terra::distance(
        x = cbind(xorig, yorig),
        y = cbind(x, y),
        pairwise = TRUE,
        lonlat = terra::is.lonlat(points)
      ),
      w_kernel = kernelfunction(pairdist, bandwidth, kernel),
      w_kernelarea = w_kernel * coverage_fraction
    ) |>
    dplyr::group_by(!!rlang::sym(id)) |>
    dplyr::summarize(
      dplyr::across(dplyr::all_of(name_surf_val), ~func(., w = w_kernelarea))
    ) |>
    dplyr::ungroup()
  # restore the original identifier
  colnames(surf_at_bufs_summary)[1] <- id
  return(surf_at_bufs_summary)
}

```

```{r, eval = FALSE, include = FALSE}
# starts from sf/stars
ncp <- readRDS(system.file("extdata/nc_random_point.rds", package = "chopin"))
ncp <- sf::st_transform(ncp, "EPSG:5070")
ncp <- terra::vect(ncp)
nccnty <- system.file("shape/nc.shp", package = "sf")
nccnty <- sf::st_read(nccnty)
nccnty <- sf::st_transform(nccnty, "EPSG:5070")
nccntytr <- terra::vect(nccnty)
ncelev <- readRDS(system.file("extdata/nc_srtm15_otm.rds", package = "chopin"))
ncelev <- terra::unwrap(ncelev)

kk <-
  extract_at_buffer_kernel(
    ncp, ncelev, 3000L, "pid", 90L, kernel = "epanechnikov", bandwidth = 4000L
  )
head(kk)


library(terra)
rrast <- terra::rast(nrow = 100, ncol = 100)
 terra::values(rrast) <- rgamma(1e4, 4, 2)
 rpnt <- terra::spatSample(rrast, 100L, as.points = TRUE)
 rpnt$pid <- sprintf("id_%03d", seq(1, 100))
 extract_at_buffer(rpnt, rrast, 4, "pid")


library(terra)
ncpath <- system.file("gpkg/nc.gpkg", package = "sf")
nc <- terra::vect(ncpath)
nc <- terra::project(nc, "EPSG:5070")
rrast <- terra::rast(nc, nrow = 100, ncol = 220)
ncr <- terra::rasterize(nc, rrast)
terra::values(rrast) <- rgamma(2.2e4, 4, 2)
rpnt <- terra::spatSample(rrast, 16L, as.points = TRUE)
rpnt$pid <- sprintf("ID-%02d", seq(1, 16))
rpoly <- terra::buffer(rpnt, 5, capstyle = "square", joinstyle = "bevel")
extract_at_poly(rpoly, rrast, "pid")


library(terra)

rrast <- terra::rast(nrow = 100, ncol = 100)
terra::values(rrast) <- rgamma(1e4, 4, 2)
terra::crs(rrast) <- ""
rpnt <- terra::spatSample(rrast, 16L, as.points = TRUE)
rpnt$pid <- rep(sprintf("ID-%d", seq(1, 4)), each = 4)
rpoly <- terra::aggregate(rpnt, "pid")
extract_at_poly(rpoly, rrast, "pid")


library(terra)
rrast <- terra::rast(nrow = 100, ncol = 100)
terra::crs(rrast) <- "EPSG:5070"
terra::values(rrast) <- rgamma(1e4, 4, 2)
rpnt <- terra::spatSample(rrast, 100L, as.points = TRUE)
rpnt$pid <- sprintf("id_%03d", seq(1, 100))
extract_at_buffer(rpnt, rrast, 4, "pid")

```

```{r, send_to = "R/processing.R"}
#' @title Extract summarized values from raster with generic polygons
#' @family Macros for calculation
#' @description For simplicity, it is assumed that the coordinate systems of
#'  the points and the raster are the same.
#' @note
#' When `Sys.setenv("CHOPIN_FORCE_CROP" = "TRUE")` is set, the raster will be
#' cropped to the extent of the polygons (with `snap` = `"out"`).
#' To note, the function is designed to work with the `exactextractr` package.
#' Arguments of `exactextractr::exact_extract` are set as below
#' (default otherwise listed except for max_cells_in_memory,
#' which is set in the `max_cells` argument):
#' * `force_df` = `TRUE`
#' * `stack_apply` = `TRUE`
#' * `progress` = `FALSE`
#' @param polys `sf`/`SpatVector` object. Polygons.
#' @param surf `SpatRaster` object or file path(s) with extensions
#' that are GDAL-compatible. A raster from which a summary will be calculated
#' @param id character(1). Unique identifier of each point.
#' @param func a generic function name in string or
#'  a function taking two arguments that are
#'  compatible with \code{\link[exactextractr]{exact_extract}}.
#'  For example, `"mean"` or `\(x, w) weighted.mean(x, w, na.rm = TRUE)`
#' @param max_cells integer(1). Maximum number of cells in memory.
#' See [`exactextractr::exact_extract`] for more details.
#' @returns a data.frame object with function value
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' ncpath <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc <- terra::vect(ncpath)
#' nc <- terra::project(nc, "EPSG:5070")
#' rrast <- terra::rast(nc, nrow = 100, ncol = 220)
#' ncr <- terra::rasterize(nc, rrast)
#' terra::values(rrast) <- rgamma(2.2e4, 4, 2)
#' rpnt <- terra::spatSample(rrast, 16L, as.points = TRUE)
#' rpnt$pid <- sprintf("ID-%02d", seq(1, 16))
#' rpoly <-
#'   terra::buffer(rpnt, 5, capstyle = "square", joinstyle = "bevel")
#' extract_at_poly(rpoly, rrast, "pid")
#' @importFrom methods is
#' @importFrom rlang sym
#' @importFrom dplyr across
#' @importFrom exactextractr exact_extract
#' @export
extract_at_poly <- function(
  polys = NULL,
  surf = NULL,
  id = NULL,
  func = "mean",
  max_cells = 2e7
) {
  # type check
  if (!methods::is(polys, "SpatVector")) {
    if (!methods::is(polys, "sf")) {
      stop("Check class of the input points.\n")
    }
    polys <- terra::vect(polys)
  }
  if (!methods::is(surf, "SpatRaster")) {
    surf <- try(terra::rast(surf))
    if (inherits(surf, "try-error")) {
      stop("Check class of the input raster.\n")
    }
  }
  if (!is.character(id)) {
    stop("id should be a character.\n")
  }
  # reproject polygons to raster's crs
  polys <- reproject_b2r(polys, surf)
  # crop raster
  if (Sys.getenv("CHOPIN_FORCE_CROP") == "TRUE") {
    polys_extent <- terra::ext(polys)
    surf_cropped <- terra::crop(surf, polys_extent, snap = "out")
  } else {
    surf_cropped <- surf
  }

  extracted_poly <-
    exactextractr::exact_extract(
      x = surf_cropped,
      y = sf::st_as_sf(polys),
      fun = func,
      force_df = TRUE,
      stack_apply = TRUE,
      append_cols = id,
      progress = FALSE,
      max_cells_in_memory = max_cells
    )
  return(extracted_poly)
}

```

```{r, send_to = "R/processing.R"}
#' Extract raster values with point buffers or polygons
#' @family Macros for calculation
#' @param vector `sf`/`SpatVector` object.
#' @param raster `SpatRaster` object. or file path(s) with extensions
#' that are GDAL-compatible.
#' @param id character(1). Unique identifier of each point.
#' @param func function taking one numeric vector argument.
#' @param mode one of `"polygon"`
#'  (generic polygons to extract raster values with) or
#'  `"buffer"` (point with buffer radius)
#' @param ... various. Passed to extract_at_buffer.
#'  See \code{?extract_at_buffer} for details.
#' @returns A data.frame object with summarized raster values with
#'  respect to the mode (polygon or buffer) and the function.
#' @author Insang Song \email{geoissong@@gmail.com}
#' @seealso [extract_at_poly], [extract_at_buffer]
#' @examples
#' ## See ?extract_at_poly and ?extract_at_buffer
#' @export
extract_at <- function(
  vector = NULL,
  raster = NULL,
  id = NULL,
  func = "mean",
  mode = c("polygon", "buffer"),
  ...
) {

  mode <- match.arg(mode)
  stopifnot(is.character(id))
  stopifnot(id %in% names(vector))

  extracted <-
    switch(mode,
      polygon =
      extract_at_poly(
        polys = vector,
        surf = raster,
        id = id,
        func = func,
        ...
      ),
      buffer =
      extract_at_buffer(
        points = vector,
        surf = raster,
        id = id,
        func = func,
        ...
      )
    )
  return(extracted)
}

#' @title Align vector CRS to raster's
#' @family Helper functions
#' @param vector `sf`/`stars`/`SpatVector`/`SpatRaster` object
#' @param raster `SpatRaster` object
#' @returns Reprojected object in the same class as \code{vector}
#' @author Insang Song
#' @examples
#' library(terra)
#' library(sf)
#' options(sf_use_s2 = FALSE)
#' ncpath <- system.file("gpkg/nc.gpkg", package = "sf")
#' elev <- system.file("ex/elev.tif", package = "terra")
#' nc <- terra::vect(ncpath)
#' elev <- terra::rast(elev)
#' reproject_b2r(nc, elev)
#' @importFrom sf st_transform
#' @importFrom terra project
#' @importFrom terra crs
#' @export
reproject_b2r <-
  function(
    vector = NULL,
    raster = NULL
  ) {
    detected_vec <- dep_check(vector)
    switch(detected_vec,
           sf = sf::st_transform(vector, terra::crs(raster)),
           terra = terra::project(vector, terra::crs(raster)))
  }

```


```{r test-extract_at, eval=FALSE, send_to = "tests/testthat/test-processing.R"}
testthat::test_that("extract_at runs well", {
  withr::local_package("sf")
  withr::local_package("stars")
  withr::local_package("terra")
  withr::local_package("dplyr")
  withr::local_package("rlang")
  withr::local_options(list(sf_use_s2 = FALSE))

  # starts from sf/stars
  ncp <- readRDS(system.file("extdata/nc_random_point.rds", package = "chopin"))
  ncp <- sf::st_transform(ncp, "EPSG:5070")
  ncp <- terra::vect(ncp)
  nccnty <- system.file("shape/nc.shp", package = "sf")
  nccnty <- sf::st_read(nccnty)
  nccnty <- sf::st_transform(nccnty, "EPSG:5070")
  nccntytr <- terra::vect(nccnty)
  ncelev <- readRDS(
    system.file("extdata/nc_srtm15_otm.rds", package = "chopin")
  )
  ncelev <- terra::unwrap(ncelev)

  nccnty4326 <- sf::st_transform(nccnty, "EPSG:4326")
  testthat::expect_no_error(reproject_b2r(nccnty4326, ncelev))

  # test two modes
  testthat::expect_no_error(
    ncexpoly <-
      extract_at(
        nccntytr,
        ncelev,
        "FIPS",
        mode = "polygon"
      )
  )

  withr::with_envvar(c("CHOPIN_FORCE_CROP" = "TRUE"),
    testthat::expect_no_error(
      extract_at(
        nccntytr,
        ncelev,
        "FIPS",
        mode = "polygon"
      )
    )
  )

  testthat::expect_no_error(
    ncexbuff <-
      extract_at(ncp,
        ncelev,
        "pid",
        mode = "buffer",
        radius = 1e4L
      )
  )
  testthat::expect_no_error(
    extract_at(st_as_sf(ncp),
      ncelev,
      "pid",
      mode = "buffer",
      radius = 1e4L
    )
  )
  withr::with_envvar(c("CHOPIN_FORCE_CROP" = "TRUE"),
    testthat::expect_no_error(
      extract_at(ncp,
        ncelev,
        "pid",
        mode = "buffer",
        radius = 1e4L
      )
    )
  )

  testthat::expect_error(
    extract_at(matrix(runif(100, 2e6, 3e6), 50, 2, TRUE),
      ncelev,
      "pid",
      mode = "buffer",
      radius = 1e4L
    )
  )

  testthat::expect_no_error(
    ncexbuffkern <-
      extract_at_buffer(
        ncp,
        ncelev,
        "pid",
        kernel = "epanechnikov",
        func = stats::weighted.mean,
        bandwidth = 1.25e4L,
        radius = 1e4L
      )
  )
  withr::with_envvar(c("CHOPIN_FORCE_CROP" = "TRUE"),
    testthat::expect_no_error(
      extract_at_buffer(
        ncp,
        ncelev,
        "pid",
        kernel = "epanechnikov",
        func = stats::weighted.mean,
        bandwidth = 1.25e4L,
        radius = 1e4L
      )
    )
  )

  testthat::expect_no_error(
    ncexbuffkern <-
      extract_at(ncp,
        ncelev,
        "pid",
        mode = "buffer",
        kernel = "epanechnikov",
        func = stats::weighted.mean,
        bandwidth = 1.25e4L,
        radius = 1e4L
      )
  )


  # errors
  testthat::expect_error(
    extract_at(nccntytr,
               ncelev,
               "FIPS",
               mode = "whatnot")
  )
  testthat::expect_error(
    extract_at_buffer(nccntytr,
               list(1),
               "FIPS",
               radius = 1e4)
  )
  testthat::expect_error(
    extract_at(nccntytr,
               ncelev,
               "GEOID",
               mode = "polygon")
  )
  testthat::expect_error(
    extract_at(nccntytr,
               ncelev,
               1,
               mode = "buffer",
               radius = 1e4L)
  )
  testthat::expect_error(
    extract_at_buffer(as.list(ncp),
                      ncelev,
                      id = "GEOID",
                      radius = 1e4L)
  )
  testthat::expect_error(
    extract_at_buffer(
      sf::st_as_sf(ncp),
      ncelev,
      id = 1,
      radius = 1e4L
    )
  )
  testthat::expect_error(
    extract_at_buffer(
      sf::st_as_sf(ncp),
      ncelev,
      id = "FIPS",
      mode = "buffer",
      radius = "Ibidem"
    )
  )
  testthat::expect_error(
    extract_at_buffer(
      sf::st_as_sf(ncp),
      ncelev,
      "FIPS",
      radius = "Ibidem"
    )
  )
  testthat::expect_error(
    extract_at_buffer(
      ncp,
      ncelev,
      "pid",
      kernel = "epanechnikov",
      func = "mean",
      bandwidth = 1.25e4L,
      radius = 1e4L,
      qsegs = 3 + 2i
    )
  )


  testthat::expect_no_error(
    extract_at_poly(
      sf::st_as_sf(nccntytr),
      ncelev,
      id = "FIPS"
    )
  )
  testthat::expect_error(
    extract_at_poly(
      as.list(nccntytr),
      ncelev,
      id = "FIPS"
    )
  )
  testthat::expect_error(
    extract_at_poly(
      nccntytr,
      list(NA),
      id = "FIPS"
    )
  )
  testthat::expect_error(
    extract_at_poly(
      nccntytr,
      matrix(rnorm(100), 10, 10),
      id = "FIPS"
    )
  )
  testthat::expect_error(
    extract_at_poly(
      nccntytr,
      ncelev,
      id = 2
    )
  )

})


```


```{r, send_to = "R/check.R"}
#' Check Coordinate Reference System
#' @family Helper functions
#' @param x `sf`/`stars`/`SpatVector`/`SpatRaster` object.
#' @returns A st_crs or crs object.
#' @description It returns st_crs object from `sf`/Spat* objects.
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' # data
#' library(sf)
#' ncpath = system.file("shape/nc.shp", package = "sf")
#' nc = read_sf(ncpath)
#' crs_check(nc)
#' @importFrom sf st_crs
#' @importFrom terra crs
#' @importFrom methods is
#' @export
crs_check <- function(x = NULL) {
  ref_class <- c("sf", "stars", "SpatVector",
                 "SpatRaster", "SpatRasterDataset")

  if (!any(ref_class %in% class(x))) {
    stop("Input is invalid.\n")
  }
  class_type <- dep_check(x)
  if (class_type == "sf" && is.na(sf::st_crs(x))) {
    stop("No CRS is defined in the input.
    Please consult the metadata or the data source.\n")
  }
  if (class_type == "terra" && any(is.na(terra::crs(x)), terra::crs(x) == "")) {
    stop("No CRS is defined in the input.
    Please consult the metadata or the data source.\n")
  }

  if (methods::is(x, "sf") || methods::is(x, "stars")) {
    crs_wkt <- sf::st_crs(x)
  } else {
    crs_wkt <- terra::crs(x)
  }

  return(crs_wkt)
}
```


```{r test-crs_check, eval = FALSE, send_to = "tests/testthat/test-check.R"}
testthat::test_that("crs_check is working as expected", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))
  ncpath <- system.file("shape/nc.shp", package = "sf")
  nc <- sf::read_sf(ncpath)
  nct <- terra::vect(nc)
  crs_checked1 <- crs_check(nc)
  dummy <- character(0)
  crs_checked2 <- crs_check(nct)

  testthat::expect_equal(crs_checked1, sf::st_crs(nc))
  testthat::expect_equal(crs_checked2, terra::crs(nct))
  testthat::expect_error(crs_check(dummy))
  ncna <- nc
  sf::st_crs(ncna) <- NA
  testthat::expect_error(crs_check(ncna))
  nctna <- nct
  terra::crs(nctna) <- ""
  testthat::expect_error(crs_check(nctna))

})

```

```{r, send_to = "R/check.R"}
#' Check if the boundary of the vector/raster object is inside the reference
#' @family Helper functions
#' @param input_object sf/stars/SpatVector/SpatRaster object.
#' @param reference sf/stars/SpatVector/SpatRaster object.
#' @returns logical
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' library(sf)
#' sf_use_s2(FALSE)
#' ncpath <- system.file("shape/nc.shp", package = "sf")
#' nc <- sf::read_sf(ncpath)
#' nc <- sf::st_transform(nc, "EPSG:4326")
#' mainland_vec <- c(xmin = -128, xmax = -62, ymin = 22, ymax = 52)
#' mainland_box <- ext2poly(mainland_vec, output_class = "sf")
#' within_res <- is_within_ref(nc, mainland_box)
#' within_res
#' @importFrom methods is
#' @importFrom sf st_bbox
#' @importFrom sf st_as_sfc
#' @importFrom sf st_covered_by
#' @export
is_within_ref <- function(input_object, reference) {
  if (!any(
    methods::is(input_object, "sf"),
    methods::is(input_object, "stars"),
    methods::is(input_object, "SpatVector"),
    methods::is(input_object, "SpatRaster")
  )) {
    stop("Input is invalid.\n")
  }

  if (!any(
    methods::is(reference, "sf"),
    methods::is(reference, "stars"),
    methods::is(reference, "SpatVector"),
    methods::is(reference, "SpatRaster")
  )) {
    stop("Reference is invalid.\n")
  }

  bbox_input <- input_object |>
    sf::st_bbox() |>
    sf::st_as_sfc()

  bbox_reference <- reference |>
    sf::st_bbox() |>
    sf::st_as_sfc()

  iswithin <- sf::st_covered_by(bbox_input, bbox_reference)
  iswithin <- length(iswithin[[1]])
  iswithin <- (iswithin == 1)
  invisible(iswithin)
}


```

```{r test-within-reference, eval = FALSE, send_to = "tests/testthat/test-check.R"}
testthat::test_that("nc data is within the mainland US", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_options(list(sf_use_s2 = FALSE))
  ncpath <- system.file("shape/nc.shp", package = "sf")
  nc <- sf::read_sf(ncpath)
  nc <- sf::st_transform(nc, "EPSG:4326")
  mainland_vec <- c(xmin = -128, xmax = -62, ymin = 22, ymax = 52)
  mainland_box <- ext2poly(mainland_vec, output_class = "sf")
  within_res <- is_within_ref(nc, mainland_box)
  testthat::expect_equal(within_res, TRUE)

  # error cases
  testthat::expect_error(is_within_ref(list(1), mainland_box))
  testthat::expect_error(is_within_ref(nc, list(1)))

})

```

```{r, eval=F, include=F}
# under construction
#' Detect and fix possible edge cases of nonminimum distance
#' @param 
#' @param 
#' @returns logical(1).
#' @author Insang Song
#' @description 
#' @importFrom 
#' @examples
#' library(terra)
#'
#' grid0 <-
#'   terra::vect("POLYGON ((0 10, 10 10, 10 0, 0 0, 0 10))")
#' # shift polygon
#' grid0d <- terra::shift(grid0, dx = -5, dy = -5)
#' grid0dl <- terra::as.lines(grid0d)
#' grid0dl <- terra::disagg(grid0dl, segments = TRUE)
#'
#' rp <-
#'   terra::spatSample(
#'     terra::ext(grid0) - 4L, 200L,
#'     lonlat = FALSE,
#'     as.points = TRUE
#'   )
#' # distance
#' grid0dl_rpd <- terra::nearest(rp, grid0dl)
#' is_dist_edge(grid0dl_rpd, y = rp, grid_in = grid0)
#' @export
is_dist_edge <- function(
  x,
  y,
  distance = NULL,
  grid_in,
  max_iter = 10
) {
    # 1. identify outermost points using convex hull
    xch <- terra::convHull(x)
    ycrop <- terra::crop(y, grid_in)
    xpbord <- terra::intersect(x, xch)

    # 2. grid polygon to lines
    grid_inb <- terra::as.lines(grid_in)
    grid_inb <- terra::disagg(grid_inb, segments = TRUE)

    if (!is.null(ycrop) || terra::is.empty(ycrop)) {
      extrusion <- terra::perim(grid_in)[1]
      dc <- rep(0, nrow(xpbord))
    } else {
      dc <- terra::nearest(xpbord, ycrop)$distance
      # this value must be positive in all cases
      extrusion <- abs(max(dc) - min(dg))
    }

    # grid_in_ext <-
    #  terra::buffer(
    #     grid_in,
    #     width = inc_grid_d,
    #     capstyle = "square",
    #     joinstyle = "bevel"
    #  )
    # ycropre <- terra::crop(y, grid_in_ext)
          
  recur <- 1
  nearest_before <- dc
  while (recur <= max_iter) {
    extrusion <- extrusion * recur
    grid_extr <-
      terra::buffer(
        grid_in,
        extrusion,
        capstyle = "square",
        joinstyle = "mitre")
    y_extr <- terra::intersect(y, grid_extr)
    nearest_this <- terra::nearest(xpbord, y_extr)

    if (any(nearest_before == nearest_this)) {
      remainder[recur] <- xpbord[nearest_this < nearest_before]
    }
    recur <- recur + 1
  }
  


poly1 <- vect("POLYGON ((0 10, 10 10, 10 0, 0 0, 0 10))")

dd <- autoexpand(poly1, 2, 3)

    # 3. get dg
    dg <- terra::nearest(xpbord, grid_inb)$distance

    # 4. case 1. y is null

    # let dc is the minimum observed distance to the target
    # dg is the distance to the closest grid boundary
    # da is the actual minimum distance to the target
    # if no da in this instance: increment by grid edge size
    # if da present: increment by max(dc-dg)
    # compare runtime of getting max(dc-dg) [MN] vs max(dc)-min(dg) [M+N]
    d_xpbord_inb <- terra::nearest(xpbord, grid_inb)
    d_xpbord_y <- terra::nearest(xpbord, ycrop)
    # max(Dg)
    max(d_xpbord_inb)
    res <- any(d_xpbord_inb$distance > d_xpbord_y$distance)

    return(res)
}





```



```{r, eval = FALSE, include = FALSE}
grid0 <-
  terra::vect("POLYGON ((0 10, 10 10, 10 0, 0 0, 0 10))")
# shift polygon
buf0 <- terra::vect("POINT (-5 -5)")
buf0 <- terra::buffer(buf0, 10)
buf0l <- terra::as.lines(buf0)

grid0d <- terra::shift(grid0, dx = -5, dy = -5)
grid0dl <- terra::as.lines(grid0d)
grid0dl <- terra::disagg(grid0dl, segments = TRUE)
# clip displaced borders
grid0dl_c <- terra::crop(grid0dl, grid0)

terra::nearest(grid0, grid0dl)
rp <-
  terra::spatSample(
    terra::ext(grid0) - 1L,
    200L, lonlat = FALSE, as.points = TRUE
  )
# distance
grid0dl_rpd <- terra::nearest(rp, buf0l)
is_dist_edge(x = rp, y = grid0dl, grid_in = grid0)

plot(grid0)
plot(rp, col = "blue", add = TRUE)
plot(buf0l, border = "red", add = TRUE)
```

```{r, send_to = "R/processing.R"}
#' Calculate Sum of Exponentially Decaying Contributions (SEDC) covariates
#' @family Macros for calculation
#' @param point_from `SpatVector` object. Locations where
#'  the sum of SEDCs are calculated.
#' @param point_to `SpatVector` object. Locations where each SEDC is calculated.
#' @param id character(1). Name of the unique id field in `point_to`.
#' @param sedc_bandwidth numeric(1).
#' Distance at which the source concentration is reduced to
#'  `exp(-3)` (approximately -95 %)
#' @param threshold numeric(1). For computational efficiency,
#'  the nearest points in threshold will be selected.
#'  \code{2 * sedc_bandwidth} is applied if this value remains `NULL`.
#' @param target_fields character. Field names to calculate SEDC.
#' @returns data.frame (tibble) object with input field names with
#'  a suffix \code{"_sedc"} where the sums of EDC are stored.
#'  Additional attributes are attached for the EDC information.
#'    - attr(result, "sedc_bandwidth"): the bandwidth where
#'  concentration reduces to approximately five percent
#'    - attr(result, "sedc_threshold"): the threshold distance
#'  at which emission source points are excluded beyond that
#' @note Distance calculation is done with `terra` functions internally.
#'  Thus, the function internally converts `sf` objects in
#'  \code{point_*} arguments to `terra`. Please note that any `NA` values
#'  in the input will be ignored in SEDC calculation.
#' @author Insang Song
#' @references
#' * [Messier KP, Akita Y, & Serre ML. (2012). Integrating Address Geocoding, Land Use Regression, and Spatiotemporal Geostatistical Estimation for Groundwater Tetrachloroethylene. _Environmental Science & Technology_ 46(5), 2772-2780.](https://dx.doi.org/10.1021/es203152a)
#' * Wiesner C. (n.d.). [Euclidean Sum of Exponentially Decaying Contributions Tutorial](https://mserre.sph.unc.edu/BMElab_web/SEDCtutorial/index.html)
#' @examples
#' library(terra)
#' library(sf)
#' set.seed(101)
#' ncpath <- system.file("gpkg/nc.gpkg", package = "sf")
#' nc <- terra::vect(ncpath)
#' nc <- terra::project(nc, "EPSG:5070")
#' pnt_from <- terra::centroids(nc, inside = TRUE)
#' pnt_from <- pnt_from[, "NAME"]
#' pnt_to <- terra::spatSample(nc, 100L)
#' pnt_to$pid <- seq(1, 100)
#' pnt_to <- pnt_to[, "pid"]
#' pnt_to$val1 <- rgamma(100L, 1, 0.05)
#' pnt_to$val2 <- rgamma(100L, 2, 1)
#'
#' vals <- c("val1", "val2")
#' summarize_sedc(pnt_from, pnt_to, "NAME", 1e5, 2e5, vals)
#' @importFrom dplyr as_tibble
#' @importFrom dplyr left_join
#' @importFrom dplyr summarize
#' @importFrom dplyr mutate
#' @importFrom dplyr group_by
#' @importFrom dplyr all_of
#' @importFrom dplyr across
#' @importFrom dplyr ungroup
#' @importFrom terra nearby
#' @importFrom terra distance
#' @importFrom terra buffer
#' @importFrom rlang sym
#' @export
summarize_sedc <-
  function(
    point_from = NULL,
    point_to = NULL,
    id = NULL,
    sedc_bandwidth = NULL,
    threshold = NULL,
    target_fields = NULL
  ) {
    # define sources, set SEDC exponential decay range
    len_point_from <- seq_len(nrow(point_from))
    len_point_to <- seq_len(nrow(point_to))

    pkginfo_from <- dep_check(point_from)
    pkginfo_to <- dep_check(point_to)

    if (any(pkginfo_from == "sf", pkginfo_to == "sf")) {
      point_from <- dep_switch(point_from)
      point_to <- dep_switch(point_to)
    }

    cn_overlap <- intersect(names(point_from), names(point_to))
    if (length(cn_overlap) > 0) {
      warning(
        sprintf(
          "There are %d fields with the same name.
The result may not be accurate.\n",
          length(cn_overlap)
        )
      )
    }
    point_from$from_id <- len_point_from
    if (is.null(threshold)) {
      threshold <- 2 * sedc_bandwidth
    }
    # select point_to with threshold
    # default threshold is 2 * sedc_bandwidth
    point_from_buf <-
      terra::buffer(
        point_from,
        width = threshold,
        quadsegs = 90
      )
    point_to <- point_to[point_from_buf, ]
    point_to$to_id <- len_point_to
    dist <- NULL

    # near features with distance argument: only returns integer indices
    near_from_to <-
      terra::nearby(point_from, point_to, distance = threshold)
    # attaching actual distance
    dist_near_to <- terra::distance(point_from, point_to)
    dist_near_to_df <- as.vector(dist_near_to)
    # adding integer indices
    dist_near_to_tdf <-
      expand.grid(
        from_id = len_point_from,
        to_id = len_point_to
      )
    dist_near_to_df <- cbind(dist_near_to_tdf, dist = dist_near_to_df)

    # summary
    near_from_to <- near_from_to |>
      dplyr::as_tibble() |>
      dplyr::left_join(data.frame(point_from)) |>
      dplyr::left_join(data.frame(point_to)) |>
      dplyr::left_join(dist_near_to_df) |>
      # per the definition in
      # https://mserre.sph.unc.edu/BMElab_web/SEDCtutorial/index.html
      # exp(-3) is about 0.05
      dplyr::mutate(w_sedc = exp((-3 * dist) / sedc_bandwidth)) |>
      dplyr::group_by(!!rlang::sym(id)) |>
      dplyr::summarize(
        dplyr::across(
          dplyr::all_of(target_fields),
          list(sedc = ~sum(w_sedc * ., na.rm = TRUE))
        )
      ) |>
      dplyr::ungroup()

    attr(near_from_to, "sedc_bandwidth") <- sedc_bandwidth
    attr(near_from_to, "sedc_threshold") <- threshold

    return(near_from_to)
  }

```

```{r, eval = FALSE, include = FALSE}
library(terra)
library(sf)
ncpath <- system.file("gpkg/nc.gpkg", package = "sf")
nc <- terra::vect(ncpath)
nc <- terra::project(nc, "EPSG:5070")
pnt_from <- terra::centroids(nc)
pnt_to <- terra::spatSample(nc, 100L)
pnt_to$pid <- seq(1, 100)
pnt_to <- pnt_to[, "pid"]
pnt_to$val1 <- rgamma(100L, 1, 0.05)
pnt_to$val2 <- rgamma(100L, 2, 1)
vals <- c("val1", "val2")
summarize_sedc(pnt_from, pnt_to, "NAME", 1e5, 2e5, vals)

```

```{r test-sedc, eval = FALSE}
testthat::test_that("SEDC are well calculated.", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_package("dplyr")
  withr::local_package("testthat")
  withr::local_options(list(sf_use_s2 = FALSE))

  # read and generate data
  ncpath <- system.file("shape/nc.shp", package = "sf")
  ncpoly <- terra::vect(ncpath) |>
    terra::project("EPSG:5070")
  ncpnts <-
    readRDS(system.file("extdata/nc_random_point.rds", package = "chopin"))
  ncpnts <- terra::vect(ncpnts)
  ncpnts <- terra::project(ncpnts, "EPSG:5070")
  ncrand <- terra::spatSample(ncpoly, 250L)
  ncrand$pollutant1 <- stats::rgamma(250L, 1, 0.01)
  ncrand$pollutant2 <- stats::rnorm(250L, 30, 4)
  ncrand$pollutant3 <- stats::rbeta(250L, 0.5, 0.5)

  polnames <- paste0("pollutant", 1:3)
  testthat::expect_no_error(
    summarize_sedc(ncpnts, ncrand, "pid", 3e4L, NULL, polnames)
  )
  testthat::expect_no_error(
    sedc_calc <-
      summarize_sedc(ncpnts, ncrand, "pid", 3e4L, 5e4L, polnames)
  )
  testthat::expect_s3_class(sedc_calc, "data.frame")

  testthat::expect_equal(
    sum(paste0(polnames, "_sedc") %in% names(sedc_calc)),
    length(polnames)
  )
  testthat::expect_true(!is.null(attr(sedc_calc, "sedc_bandwidth")))
  testthat::expect_true(!is.null(attr(sedc_calc, "sedc_threshold")))

  ncpnts <-
    readRDS(system.file("extdata/nc_random_point.rds", package = "chopin"))
  ncpnts <- sf::st_transform(ncpnts, "EPSG:5070")
  ncrandsf <- sf::st_as_sf(ncrand)

  testthat::expect_no_error(
    summarize_sedc(ncpnts, ncrandsf, "pid", 3e4L, 5e4L, polnames)
  )

  ncpnts2 <- ncpnts
  ncpnts2$FIPS <- as.character(rpois(nrow(ncpnts2), 20))
  testthat::expect_warning(
    summarize_sedc(ncpnts2, ncrandsf, "pid", 3e4L, 5e4L, polnames)
  )
})

```


```{r, send_to = "R/processing.R"}
#' Area weighted summary using two polygon sf or SpatVector objects
#' @family Macros for calculation
#' @param poly_in A sf/SpatVector object at weighted means will be calculated.
#' @param poly_weight A sf/SpatVector object from
#'  which weighted means will be calculated.
#' @param target_fields character. Field names to calculate area-weighted .
#' @param id_poly_in character(1).
#'  The unique identifier of each polygon in `poly_in`.
#'  Default is `"ID"`.
#' @param fun function(1). The function to calculate the weighted summary.
#' Default is `stats::weighted.mean`. The function must have a `w` argument.
#' @returns A data.frame with all numeric fields of area-weighted means.
#' @description When `poly_in` and `poly_weight` are different classes,
#'  `poly_weight` will be converted to the class of `poly_in`.
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' # package
#' library(sf)
#' sf_use_s2(FALSE)
#' nc <- sf::st_read(system.file("shape/nc.shp", package="sf"))
#' nc <- sf::st_transform(nc, 5070)
#' pp <- sf::st_sample(nc, size = 300)
#' pp <- sf::st_as_sf(pp)
#' pp[["id"]] <- seq(1, nrow(pp))
#' sf::st_crs(pp) <- "EPSG:5070"
#' ppb <- sf::st_buffer(pp, nQuadSegs=180, dist = units::set_units(20, "km"))
#'
#' system.time(ppb_nc_aw <- summarize_aw(ppb, nc, c("BIR74", "BIR79"), "id"))
#' summary(ppb_nc_aw)
#' #### Example of summarize_aw ends ####
#' @importFrom terra expanse
#' @importFrom rlang sym
#' @importFrom dplyr where
#' @importFrom dplyr group_by
#' @importFrom dplyr summarize
#' @importFrom dplyr across
#' @importFrom dplyr ungroup
#' @importFrom terra intersect
#' @importFrom sf st_interpolate_aw
#' @importFrom stats weighted.mean
#' @export
summarize_aw <-
  function(
    poly_in = NULL,
    poly_weight = NULL,
    target_fields = NULL,
    id_poly_in = "ID",
    fun = stats::weighted.mean
  ) {
    if (!any(
      methods::is(poly_in, "sf"),
      methods::is(poly_in, "SpatVector")
    )) {
      stop("poly_in is in invalid class.\n")
    }
    if (!any(
      methods::is(poly_weight, "sf"),
      methods::is(poly_weight, "SpatVector")
    )) {
      stop("poly_weight is in invalid class.\n")
    }

    summarize_aw_terra <-
      function(
        poly_in = NULL,
        poly_weight = NULL,
        target_fields = NULL,
        id_poly_in = id_poly_in
      ) {
        poly_intersected <- terra::intersect(poly_in, poly_weight)
        poly_intersected[["area_segment_"]] <-
          terra::expanse(poly_intersected)
        poly_intersected <- data.frame(poly_intersected) |>
          dplyr::group_by(!!rlang::sym(id_poly_in)) |>
          dplyr::summarize(
            dplyr::across(
              dplyr::all_of(target_fields),
              ~fun(., w = area_segment_)
            )
          ) |>
          dplyr::ungroup()
        return(poly_intersected)
      }

    class_poly_in <- dep_check(poly_in)
    class_poly_weight <- dep_check(poly_weight)

    if (class_poly_in != class_poly_weight) {
      poly_weight <- dep_switch(poly_weight)
    }

    switch(class_poly_in,
      sf =
        suppressWarnings(
          sf::st_interpolate_aw(
            poly_weight[, target_fields],
            poly_in, extensive = FALSE
          )
        ),
      terra =
        summarize_aw_terra(
          poly_in, poly_weight,
          target_fields = target_fields,
          id_poly_in = id_poly_in
        )
    )

  }


```


```{r aw-test, eval = FALSE, send_to = "tests/testthat/test-processing.R"}

testthat::test_that("summarize_aw works as expected.", {
  withr::local_package("sf")
  withr::local_package("terra")
  withr::local_package("units")
  withr::local_package("dplyr")
  withr::local_package("testthat")
  withr::local_options(list(sf_use_s2 = FALSE))

  nc <- sf::st_read(system.file("shape/nc.shp", package = "sf"))
  nc <- sf::st_transform(nc, 5070)
  pp <- sf::st_sample(nc, size = 300)
  pp <- sf::st_as_sf(pp)
  pp[["id"]] <- seq(1, nrow(pp))
  sf::st_crs(pp) <- "EPSG:5070"
  flds <- c("BIR74", "SID74", "BIR79", "SID79")
  ppb <- sf::st_buffer(pp, nQuadSegs = 180, dist = units::set_units(20, "km"))

  testthat::expect_no_error(
    system.time({
      ppb_nc_aw <- summarize_aw(ppb, nc, target_fields = flds, "id")
    })
  )
  expect_s3_class(ppb_nc_aw, "sf")

  # terra
  ppb_t <- terra::vect(ppb)
  nc_t <- terra::vect(nc)
  testthat::expect_no_error(
    system.time({
      ppb_nc_aw <- summarize_aw(ppb_t, nc_t, target_fields = flds, "id")
    })
  )
  expect_s3_class(ppb_nc_aw, "data.frame")

  # auto convert formats
  testthat::expect_no_error(
    system.time({
      ppb_nc_aw <- summarize_aw(ppb_t, nc, target_fields = flds, "id")
    })
  )
  expect_s3_class(ppb_nc_aw, "data.frame")

  # error case
  testthat::expect_error(summarize_aw(as.list(ppb_t), nc, fld, "id"))
  testthat::expect_error(summarize_aw(ppb_t, list(1, 3), fld, "id"))
})



```


```{r, send_to = "R/check.R"}
#' Detect classes in function arguments
#' @family Helper functions
#' @param args Any list, but preferably generated by \code{list(...)} inside
#' a function.
#' @param search character(1). Class name to search. Partial match is supported.
#' @returns logical vector.
#' @author Insang Song
#' @description When a R function is defined in an ordinary
#' fashion (i.e., assigning a function by \code{<- function(...)})
#' would be subject to ambiguity particularly if the function
#' name is the same as the generic function name(s).
#' This function supports detecting classes of arguments in
#' a loosely defined function.
#' @examples
#' df <- data.frame(a = 1, b = 3)
#' any_class_args(list(df), "data.frame")
#' @export
any_class_args <- function(
  args = NULL,
  search = NULL
) {
  searchphrase <- sprintf("(%s)", search)
  args_scanned <- lapply(args, function(x) any(grepl(searchphrase, class(x))))
  args_scanned <- sapply(args_scanned, any)
  return(args_scanned)
}


```


```{r test-detect-class, eval = FALSE, send_to = "tests/testthat/test-any_class_args.R"}
testthat::test_that("classes are detected.", {
  withr::local_package("terra")
  random_df <- data.frame(x = runif(10), y = runif(10))
  random_tv <- terra::vect(random_df, geom = c("x", "y"))
  test_args <- list(vector = random_tv,
                    func = mean,
                    pipi = pi,
                    zodiac = "Horse")
  set_detected <- any_class_args(test_args, "SpatVector")
  # test partial match
  set_detectedp <- any_class_args(test_args, "Spat")

  testthat::expect_true(is.logical(set_detected))
  testthat::expect_true(is.logical(set_detectedp))
  # both are the same
  testthat::expect_true(all.equal(set_detected, set_detectedp))

  vect_pop <- test_args[set_detected][[1]]
  testthat::expect_s4_class(vect_pop, "SpatVector")

  # does it well in a function as designed?
  downy <- function(...) {
    largs <- list(...)
    any_class_args(largs, "SpatVector")
  }
  bear <- downy(v = random_tv, f = mean, pipi = pi)

  testthat::expect_true(is.logical(bear))
  testthat::expect_true(bear[[1]] == TRUE)

})

```


```{r, send_to = "R/scale_process.R"}
#' Parallelization error fallback
#' @family Parallelization
#' @param err Error status or message.
#' @param fun function.
#' @param debug logical(1). Print error messages (`TRUE`) or not (`FALSE`)
#' @returns data.frame with one column
#' @note This function assumes that the `fun` has an argument named
#' `"id"`.
#' @author Insang Song
#' @examples
#' err <- simpleError("No input.")
#' par_fallback(err, extract_at, debug = TRUE)
#' @export
par_fallback <-
  function(
    err = NULL,
    fun = NULL,
    debug = FALSE
  ) {
    if (debug) {
      print(err)
    }
    fallback <- data.frame(ID = NA)
    fun_args <- formals(fun)
    indx <- grepl("id", names(fun_args))
    if (any(indx)) {
      detected_id <- fun_args[indx]
    } else {
      detected_id <- "id"
    }
    colnames(fallback)[1] <- detected_id
    return(fallback)
  }

```

```{r test-par_fallback, eval = FALSE, send_to = "tests/testthat/test-par_fallback.R"}
testthat::test_that(
  "par_fallback works",
  {
    withr::local_package("terra")
    dc <- terra::vect("POINT (12 8)", crs = "EPSG:4326")
    dc$site_id <- "SITE1"
    rdd <- terra::rast(nrow = 10, ncol = 10, crs = "EPSG:4326")
    terra::ext(rdd) <-
      c(xmin = 10, xmax = 20, ymin = 0, ymax = 10)
    terra::values(rdd) <- runif(100L)

    foo1 <- extract_at
    foo2 <- mean
    testthat::expect_no_error(
      par_fallback(
        err = foo1(dc, rdd, id = "site_id", mode = "buffer", radius = 5e4),
        fun = foo1,
        debug = TRUE
      )
    )
    testthat::expect_no_error(
      par_fallback(
        err = foo1(),
        fun = foo2,
        debug = FALSE
      )
    )
  }
)


```

```{r, send_to = "R/scale_process.R"}
#' @title Process a given function in the entire or partial computational grids
#' @family Parallelization
#' @description
#' [future::multicore], [future::multisession], [future::cluster]
#' with [doParallel::registerDoParallel] will parallelize the work
#' in each grid. For details of the terminology in \code{future} package,
#' refer to \link[future]{plan}. This function assumes that
#' users have one raster file and a sizable and spatially distributed
#' target locations. Each thread will process
#' the nearest integer of $|N_g| / |N_t|$ grids
#' where $|N_g|$ denotes the number of grids and $|N_t|$ denotes
#' the number of threads.
#' @note In dynamic dots (\code{...}), the first and second
#' arguments should be the \code{fun_dist} arguments where
#' sf/SpatVector objects are accepted.
#' Virtually any sf/terra functions that accept two arguments
#' can be put in \code{fun_dist}, but please be advised that
#' some spatial operations do not necessarily give the
#' exact result from what would have been done single-thread.
#' For example, distance calculated through this function may return the
#' lower value than actual because the computational region was reduced.
#' This would be the case especially where the target features
#' are spatially sparsely distributed.
#' @param grids sf/SpatVector object. Computational grids.
#'  It takes a strict assumption that the grid input is
#'  an output of \code{par_make_gridset}
#' @param grid_target_id character(1) or numeric(2).
#'  Default is NULL. If NULL, all grid_ids are used.
#'  \code{"id_from:id_to"} format or
#'  \code{c(unique(grid_id)[id_from], unique(grid_id)[id_to])}
#' @param debug logical(1). Prints error messages
#' if there were any errors during the calculation.
#' @param combine function. A function to combine results.
#' Default is \code{dplyr::bind_rows}.
#' @param fun_dist `sf`, `terra` or `chopin` functions.
#' @param ... Arguments passed to the argument \code{fun_dist}.
#' The **second** place should get a vector or raster dataset from which
#' you want to extract or calculate values. For example, a raster dataset
#' when vector-raster overlay is performed.
#' @returns a data.frame object with computation results.
#'  For entries of the results, consult the function used in
#'  \code{fun_dist} argument.
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' \dontrun{
#' ncpath <- system.file("shape/nc.shp", package = "sf")
#' ncpoly <- terra::vect(ncpath) |>
#'   terra::project("EPSG:5070")
#' ncpnts <-
#'   readRDS(
#'     system.file("extdata/nc_random_point.rds", package = "chopin")
#'   )
#' ncpnts <- terra::vect(ncpnts)
#' ncpnts <- terra::project(ncpnts, "EPSG:5070")
#' ncelev <-
#'   terra::unwrap(
#'     readRDS(system.file("extdata/nc_srtm15_otm.rds", package = "chopin"))
#'   )
#' terra::crs(ncelev) <- "EPSG:5070"
#' names(ncelev) <- c("srtm15")
#'
#' ncsamp <-
#'   terra::spatSample(
#'     terra::ext(ncelev),
#'     1e4L,
#'     lonlat = FALSE,
#'     as.points = TRUE
#'   )
#' ncsamp$kid <- sprintf("K-%05d", seq(1, nrow(ncsamp)))
#' nccompreg <-
#'   par_make_gridset(
#'     input = ncpnts,
#'     mode = "grid",
#'     nx = 6L,
#'     ny = 4L,
#'     padding = 3e4L
#'   )
#' res <-
#'   par_grid(
#'     grids = nccompreg,
#'     grid_target_id = NULL,
#'     fun_dist = extract_at_buffer,
#'     points = ncpnts,
#'     surf = ncelev,
#'     qsegs = 90L,
#'     radius = 5e3L,
#'     id = "pid"
#'   )
#' }
#' @import future
#' @importFrom future.apply future_lapply
#' @importFrom rlang inject
#' @importFrom rlang !!!
#' @importFrom dplyr bind_rows
#' @importFrom sf sf_use_s2
#' @export
par_grid <-
  function(
    grids,
    grid_target_id = NULL,
    debug = FALSE,
    combine = dplyr::bind_rows,
    fun_dist,
    ...
  ) {
    if (is.character(grid_target_id) && !grepl(":", grid_target_id)) {
      stop("Character grid_target_id should be in a form of 'startid:endid'.\n")
    }
    if (is.numeric(grid_target_id)) {
      if (length(grid_target_id) != 2) {
        stop(
          "Numeric grid_target_id should be in a form of c(startid, endid).\n"
        )
      }
      grid_target_ids <- unlist(grids$original[["CGRIDID"]])[grid_target_id]
    }
    # subset using grids and grid_id
    if (is.null(grid_target_id)) {
      grid_target_ids <- unlist(grids$original[["CGRIDID"]])
    }
    if (is.character(grid_target_id)) {
      grid_id_parsed <- strsplit(grid_target_id, ":", fixed = TRUE)[[1]]
      grid_target_ids <-
        c(which(unlist(grids$original[["CGRIDID"]]) == grid_id_parsed[1]),
          which(unlist(grids$original[["CGRIDID"]]) == grid_id_parsed[2]))
    }

    grids_target <-
      grids$original[grid_target_ids %in% unlist(grids$original[["CGRIDID"]]), ]
    grids_target_list <- split(grids_target, unlist(grids_target[["CGRIDID"]]))

    results_distributed <-
      future.apply::future_lapply(
        grids_target_list,
        function(grid) {
          sf::sf_use_s2(FALSE)
          args_input <- list(...)
          if (dep_check(grid) != dep_check(args_input[[1]])) {
            grid <- dep_switch(grid)
          }
          grid <- reproject_std(grid, terra::crs(args_input[[1]]))
          run_result <- tryCatch({
            ## Strongly assuming that
            # the first is "at", the second is "from"
            args_input[[1]] <-
              args_input[[1]][grid, ]
            if (methods::is(args_input[[2]], "SpatVector")) {
              gpad_in <- grids$padded[grids$padded$CGRIDID == grid$CGRIDID, ]
              args_input[[2]] <- args_input[[2]][gpad_in, ]
            }
            if (!"id" %in% names(formals(fun_dist))) {
              args_input$id <- NULL
            }

            res <- rlang::inject(fun_dist(!!!args_input))
            cat(
              sprintf(
                "Your input function was successfully run at CGRIDID: %s\n",
                as.character(unlist(grid[["CGRIDID"]]))
              )
            )

            try(res <- as.data.frame(res))
            return(res)
          },
          error = function(e) {
            par_fallback(e, fun_dist, debug)

          })

          return(run_result)
        },
        future.seed = TRUE,
        future.packages = c("chopin", "dplyr", "sf", "terra")
      )
    results_distributed <- do.call(combine, results_distributed)

    return(results_distributed)
  }


#' @title Process a given function using a hierarchy in input data
#' @family Parallelization
#' @description "Hierarchy" refers to a system,
#'  which divides the entire study region into multiple subregions.
#'  It is oftentimes reflected in an area code system
#'  (e.g., FIPS for US Census geographies, HUC-4, -6, -8, etc.).
#' [future::multicore], [future::multisession], [future::cluster]
#' with [doParallel::registerDoParallel] will parallelize the work
#' in each grid. For details of the terminology in \code{future} package,
#'  refer to \link[future]{plan}.
#'  This function assumes that users have one raster file and
#'  a sizable and spatially distributed target locations.
#'  Each thread will process the number of lower level features
#'  in each higher level feature. Please be advised that
#'  accessing the same file simultaneously with
#'  multiple processes may result in errors.
#' @note In dynamic dots (\code{...}), the first and second
#' arguments should be the \code{fun_dist} arguments where
#' `sf`/`SpatVector` objects are accepted.
#' Virtually any `sf`/`terra` functions that accept two arguments
#' can be put in \code{fun_dist}, but please be advised that
#' some spatial operations do not necessarily give the
#' exact result from what would have been done single-thread.
#' For example, distance calculated through this function may return the
#' lower value than actual because the computational region was reduced.
#' This would be the case especially where the target features
#' are spatially sparsely distributed.
#' @param regions sf/SpatVector object.
#'  Computational regions. Only polygons are accepted.
#' @param split_level character(nrow(regions)) or character(1).
#'  The regions will be split by the common level value.
#'  The level should be higher than the original data level.
#'  A field name with the higher level information is also accepted.
#' @param debug logical(1). Prints error messages
#' if there were any errors during the calculation.
#' @param combine function. The function to combine the results.
#' @param fun_dist sf, terra, or chopin functions.
#' @param ... Arguments passed to the argument \code{fun_dist}.
#' The **second** place should get a vector or raster dataset from which
#' you want to extract or calculate values. For example, a raster dataset
#' when vector-raster overlay is performed.
#' @returns a data.frame object with computation results.
#'  For entries of the results, consult the function used in
#'  \code{fun_dist} argument.
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' \dontrun{
#' library(terra)
#' library(sf)
#' library(chopin)
#' library(future)
#' library(doFuture)
#' sf::sf_use_s2(FALSE)
#' registerDoFuture()
#' plan(multicore)
#'
#' ncpath <- system.file("extdata/nc_hierarchy.gpkg", package = "chopin")
#' nccnty <- terra::vect(ncpath, layer = "county")
#' nctrct <- sf::st_read(ncpath, layer = "tracts")
#' nctrct <- terra::vect(nctrct)
#' ncelev <-
#'   terra::unwrap(
#'     readRDS(
#'       system.file("extdata/nc_srtm15_otm.rds", package = "chopin")
#'     )
#'   )
#' terra::crs(ncelev) <- "EPSG:5070"
#' names(ncelev) <- c("srtm15")
#'
#' ncsamp <-
#'   terra::spatSample(
#'     terra::ext(ncelev),
#'     1e4L,
#'     lonlat = FALSE,
#'     as.points = TRUE
#'   )
#' ncsamp$kid <- sprintf("K-%05d", seq(1, nrow(ncsamp)))
#' res <-
#'   par_hierarchy(
#'     regions = nccnty,
#'     split_level = "GEOID",
#'     fun_dist = extract_at_poly,
#'     polys = nctrct,
#'     surf = ncelev,
#'     id = "GEOID",
#'     func = "mean"
#'   )
#' )
#' }
#' @import future
#' @importFrom future.apply future_lapply
#' @importFrom rlang inject
#' @importFrom rlang !!!
#' @importFrom dplyr bind_rows
#' @importFrom sf sf_use_s2
#' @export
par_hierarchy <-
  function(
    regions,
    split_level = NULL,
    debug = FALSE,
    combine = dplyr::bind_rows,
    fun_dist,
    ...
  ) {

    if (!any(length(split_level) == 1, length(split_level) == nrow(regions))) {
      stop("The length of split_level is not valid.")
    }
    split_level <-
      ifelse(length(split_level) == nrow(regions),
             split_level,
             unlist(regions[[split_level]]))
    regions_list <- base::split(split_level, split_level)

    results_distributed <-
      future.apply::future_lapply(
        regions_list,
        function(subregion) {
          sf::sf_use_s2(FALSE)
          run_result <-
            tryCatch(
              {
                # TODO: padded subregion to deal with
                # edge cases; how to determine padding?
                subregion <-
                  regions[startsWith(split_level, subregion), ]
                args_input <- list(...)
                ## Strongly assuming that
                # the first is "at", the second is "from"
                args_input[[1]] <-
                  args_input[[1]][subregion, ]
                if (!"id" %in% names(formals(fun_dist))) {
                  args_input$id <- NULL
                }

                res <- rlang::inject(fun_dist(!!!args_input))
                try(res <- as.data.frame(res))
                return(res)
              },
              error =
              function(e) {
                par_fallback(e, fun_dist, debug)
              }
            )
          return(run_result)
        },
        future.seed = TRUE,
        future.packages = c("chopin", "dplyr", "sf", "terra")
      )
    results_distributed <- do.call(combine, results_distributed)

    return(results_distributed)
  }




#' @title Process a given function over multiple large rasters
#' @family Parallelization
#' @description Large raster files usually exceed the memory capacity in size.
#'  Cropping a large raster into a small subset even consumes
#'  a lot of memory and adds processing time.
#'  This function leverages `terra` `SpatRaster` proxy
#'  to distribute computation jobs over multiple cores.
#'  It is assumed that users have multiple large raster files
#'  in their disk, then each file path is assigned to a thread.
#'  Each thread will directly read raster values from
#'  the disk using C++ pointers that operate in terra functions.
#'  For use, it is strongly recommended to use vector data with
#'  small and confined spatial extent for computation to avoid
#'  out-of-memory error. For this, users may need
#'  to make subsets of input vector objects in advance.
#' @param filenames character(n). A vector or list of
#'  full file paths of raster files. n is the total number of raster files.
#' @param debug logical(1). Prints error messages
#' if there were any errors during the calculation.
#' @param combine function. The function to combine the results.
#' Default is `dplyr::bind_rows`.
#' @param fun_dist sf, terra, or chopin functions.
#' @param ... Arguments passed to the argument \code{fun_dist}.
#' The **second** place should get a vector or raster dataset from which
#' you want to extract or calculate values. For example, a raster dataset
#' when vector-raster overlay is performed.
#' @returns a data.frame object with computation results.
#'  For entries of the results,
#'  consult the function used in \code{fun_dist} argument.
#' @author Insang Song \email{geoissong@@gmail.com}
#'
#' @examples
#' \dontrun{
#' library(terra)
#' library(sf)
#' library(chopin)
#' library(future)
#' library(doFuture)
#' sf::sf_use_s2(FALSE)
#' registerDoFuture()
#' plan(multicore)
#'
#' ncpath <- system.file("extdata/nc_hierarchy.gpkg", package = "chopin")
#' nccnty <- terra::vect(ncpath, layer = "county")
#' ncelev <-
#'   terra::unwrap(
#'     readRDS(
#'       system.file("extdata/nc_srtm15_otm.rds", package = "chopin")
#'     )
#'   )
#' terra::crs(ncelev) <- "EPSG:5070"
#' names(ncelev) <- c("srtm15")
#' tdir <- tempdir(check = TRUE)
#' terra::writeRaster(ncelev, file.path(tdir, "test1.tif"), overwrite = TRUE)
#' terra::writeRaster(ncelev, file.path(tdir, "test2.tif"), overwrite = TRUE)
#' terra::writeRaster(ncelev, file.path(tdir, "test3.tif"), overwrite = TRUE)
#' testfiles <- list.files(tdir, pattern = "tif$", full.names = TRUE)
#'
#' res <- par_multirasters(
#'   filenames = testfiles,
#'   fun_dist = extract_at_poly,
#'   polys = nccnty,
#'   surf = ncelev,
#'   id = "GEOID",
#'   func = "mean"
#' )
#' }
#' @import future
#' @importFrom future.apply future_lapply
#' @import doFuture
#' @importFrom terra rast
#' @export
par_multirasters <-
  function(
    filenames,
    debug = FALSE,
    combine = dplyr::bind_rows,
    fun_dist,
    ...
  ) {

    file_list <- split(filenames, filenames)
    results_distributed <-
      future.apply::future_lapply(
        file_list,
        function(path) {
          run_result <-
            try({
              args_input <- list(...)
              vect_target_tr <- any_class_args(args_input, "SpatVector")
              vect_target_sf <- any_class_args(args_input, "sf")
              vect_target <- (vect_target_tr | vect_target_sf)
              vect_ext <- args_input[vect_target]
              vect_ext <- terra::ext(vect_ext[[1]])

              rast_target <- which(any_class_args(args_input, "SpatRaster"))
              args_input[[rast_target]] <-
                terra::rast(x = path, win = vect_ext)
              if (!"id" %in% names(formals(fun_dist))) {
                args_input$id <- NULL
              }

              res <- rlang::inject(fun_dist(!!!args_input))
              try(res <- as.data.frame(res))
              res$base_raster <- path
              return(res)
            }
            )
          if (inherits(run_result, "try-error")) {
            par_fallback(run_result, fun_dist, debug)
          }
        },
        future.seed = TRUE,
        future.packages =
        c("chopin", "dplyr", "sf", "terra"),
        future.globals = FALSE,
        future.scheduling = 2
        # "terra", "sf", "dplyr", "rlang",
        #   "chopin", "future",
        #   "exactextractr")
      )
    results_distributed <- do.call(combine, results_distributed)

    return(results_distributed)
  }



```


```{r test-distribute, eval=FALSE, send_to = "tests/testthat/test-distribute_suites.R"}
testthat::test_that("Processes are properly spawned and compute", {
  withr::local_package("terra")
  withr::local_package("sf")
  withr::local_package("future")
  withr::local_package("future.apply")
  withr::local_package("dplyr")
  withr::local_options(list(sf_use_s2 = FALSE))

  ncpath <- system.file("shape/nc.shp", package = "sf")
  ncpoly <- terra::vect(ncpath) |>
    terra::project("EPSG:5070")
  ncpnts <-
    readRDS(
            system.file("extdata/nc_random_point.rds", package = "chopin"))
  ncpnts <- terra::vect(ncpnts)
  ncpnts <- terra::project(ncpnts, "EPSG:5070")
  ncelev <-
    terra::unwrap(
      readRDS(system.file("extdata/nc_srtm15_otm.rds", package = "chopin"))
    )
  terra::crs(ncelev) <- "EPSG:5070"
  names(ncelev) <- c("srtm15")

  ncsamp <-
    terra::spatSample(
      terra::ext(ncelev),
      1e4L,
      lonlat = FALSE,
      as.points = TRUE
    )
  ncsamp$kid <- sprintf("K-%05d", seq(1, nrow(ncsamp)))

  nccompreg <-
    par_make_gridset(
      input = ncpnts,
      mode = "grid",
      nx = 6L,
      ny = 4L,
      padding = 3e4L
    )
  res <-
    suppressWarnings(
      par_grid(
        grids = nccompreg,
        grid_target_id = NULL,
        fun_dist = extract_at_buffer,
        points = ncpnts,
        surf = ncelev,
        qsegs = 90L,
        radius = 5e3L,
        id = "pid"
      )
    )

  testthat::expect_error(
    suppressWarnings(
      par_grid(
        grids = nccompreg,
        grid_target_id = "1/10",
        fun_dist = extract_at_buffer,
        points = ncpnts,
        surf = ncelev,
        qsegs = 90L,
        radius = 5e3L,
        id = "pid"
      )
    )
  )

  testthat::expect_error(
    suppressWarnings(
      par_grid(
        grids = nccompreg,
        grid_target_id = c(1, 100, 125),
        fun_dist = extract_at_buffer,
        points = ncpnts,
        surf = ncelev,
        qsegs = 90L,
        radius = 5e3L,
        id = "pid"
      )
    )
  )


  testthat::expect_no_error(
    suppressWarnings(
      par_grid(
        grids = nccompreg,
        grid_target_id = "1:10",
        fun_dist = extract_at_buffer,
        points = ncpnts,
        surf = ncelev,
        qsegs = 90L,
        radius = 5e3L,
        id = "pid"
      )
    )
  )


  testthat::expect_no_error(
    suppressWarnings(
      par_grid(
        grids = nccompreg,
        grid_target_id = c(1, 3),
        fun_dist = extract_at_buffer,
        points = ncpnts,
        surf = ncelev,
        qsegs = 90L,
        radius = 5e3L,
        id = "pid"
      )
    )
  )

  testthat::expect_true(is.list(nccompreg))
  testthat::expect_s4_class(nccompreg$original, "SpatVector")
  testthat::expect_s3_class(res, "data.frame")
  testthat::expect_true(!anyNA(unlist(res)))

  testthat::expect_no_error(
    suppressWarnings(
      resnas <-
        par_grid(
          grids = nccompreg,
          grid_target_id = "1:10",
          fun_dist = extract_at_buffer,
          points = ncpnts,
          surf = ncelev,
          qsegs = 90L,
          radius = -5e3L,
          id = "pid"
        )
    )
  )

  testthat::expect_s3_class(resnas, "data.frame")
  testthat::expect_true(anyNA(resnas))

  testthat::expect_no_error(
    suppressWarnings(
      resnas0 <-
        par_grid(
          grids = nccompreg,
          grid_target_id = "1:10",
          fun_dist = terra::nearest,
          x = ncpnts,
          y = ncsamp,
          id = "pid"
        )
    )
  )

})


```

```{r test-runhierarchy, eval = FALSE, send_to = "tests/testthat/test-distribute_suites.R"}
testthat::test_that(
  "Processes are properly spawned and compute over hierarchy", {
    withr::local_package("terra")
    withr::local_package("sf")
    withr::local_package("future")
    withr::local_package("future.apply")
    withr::local_package("dplyr")
    withr::local_options(list(sf_use_s2 = FALSE))

    ncpath <- system.file("extdata/nc_hierarchy.gpkg", package = "chopin")
    nccnty <- terra::vect(ncpath, layer = "county")
    nctrct <- sf::st_read(ncpath, layer = "tracts")
    nctrct <- terra::vect(nctrct)
    ncelev <-
      terra::unwrap(
        readRDS(
          system.file("extdata/nc_srtm15_otm.rds", package = "chopin")
        )
      )
    terra::crs(ncelev) <- "EPSG:5070"
    names(ncelev) <- c("srtm15")

    ncsamp <-
      terra::spatSample(
        terra::ext(ncelev),
        1e4L,
        lonlat = FALSE,
        as.points = TRUE
      )
    ncsamp$kid <- sprintf("K-%05d", seq(1, nrow(ncsamp)))

    testthat::expect_no_error(
      res <-
        suppressWarnings(
          par_hierarchy(
            regions = nccnty,
            split_level = "GEOID",
            fun_dist = extract_at_poly,
            polys = nctrct,
            surf = ncelev,
            id = "GEOID",
            func = "mean"
          )
        )
    )

    testthat::expect_error(
      suppressWarnings(
        par_hierarchy(
          regions = nccnty,
          split_level = c(1, 2, 3),
          fun_dist = extract_at_poly,
          polys = nctrct,
          surf = ncelev,
          id = "GEOID",
          func = "mean"
        )
      )
    )

    testthat::expect_s3_class(res, "data.frame")
    testthat::expect_equal(!any(is.na(unlist(res))), TRUE)

    testthat::expect_no_error(
      suppressWarnings(
        resnas <-
          par_hierarchy(
            regions = nccnty,
            split_level = "GEOID",
            fun_dist = terra::nearest,
            polys = nctrct,
            surf = ncelev
          )
      )
    )

    testthat::expect_s3_class(resnas, "data.frame")
    testthat::expect_true(anyNA(resnas))

    testthat::expect_no_error(
      suppressWarnings(
        resnasx <-
          par_hierarchy(
            regions = nccnty,
            debug = TRUE,
            split_level = "GEOID",
            fun_dist = extract_at_buffer,
            points = terra::centroids(nctrct),
            surf = ncelev,
            id = "GEOID",
            radius = -1e3L
          )
      )
    )

    testthat::expect_no_error(
      suppressWarnings(
        resnasz <-
          par_hierarchy(
            regions = nccnty,
            debug = TRUE,
            split_level = "GEOID",
            fun_dist = terra::nearest,
            x = nctrct,
            y = ncsamp
          )
      )
    )
  }
)



```


```{r test-generic-function, eval = FALSE, send_to = "tests/testthat/test-distribute_suites.R"}
testthat::test_that("generic function should be parallelized properly", {
  withr::local_package("terra")
  withr::local_package("sf")
  withr::local_package("future")
  withr::local_package("future.apply")
  withr::local_package("dplyr")
  withr::local_options(list(sf_use_s2 = FALSE))

  # main test
  pnts <- readRDS(system.file("extdata/nc_random_point.rds", package = "chopin"))
  pnts <- terra::vect(pnts)
  rd1 <-
    terra::vect(system.file("extdata/ncroads_first.gpkg", package = "chopin"))

  pnts <- terra::project(pnts, "EPSG:5070")
  rd1 <- terra::project(rd1, "EPSG:5070")
  # expect

  nccompreg <-
    par_make_gridset(
      input = pnts,
      mode = "grid",
      nx = 6L,
      ny = 4L,
      padding = 3e4L
    )
  future::plan(future::multicore, workers = 6L)
  testthat::expect_no_error(
    res <-
      suppressWarnings(
        par_grid(
          grids = nccompreg,
          fun_dist = terra::nearest,
          x = pnts,
          y = rd1
        )
      )
  )
  testthat::expect_s3_class(res, "data.frame")
  testthat::expect_equal(nrow(res), nrow(pnts))

})

```

```{r test-multirasters, eval = FALSE, send_to = "tests/testthat/test-distribute_suites.R"}
testthat::test_that(
  "Processes are properly spawned and compute over multirasters",
  {
    withr::local_package("terra")
    withr::local_package("sf")
    withr::local_package("future")
    withr::local_package("future.apply")
    withr::local_package("dplyr")
    withr::local_options(
      list(
        sf_use_s2 = FALSE,
        future.resolve.recursive = 2L
      )
    )

    ncpath <- system.file("extdata/nc_hierarchy.gpkg", package = "chopin")
    nccnty <- terra::vect(ncpath, layer = "county")
    ncelev <-
      terra::unwrap(
        readRDS(
          system.file("extdata/nc_srtm15_otm.rds", package = "chopin")
        )
      )
    terra::crs(ncelev) <- "EPSG:5070"
    names(ncelev) <- c("srtm15")
    tdir <- tempdir(check = TRUE)
    terra::writeRaster(ncelev, file.path(tdir, "test1.tif"), overwrite = TRUE)
    terra::writeRaster(ncelev, file.path(tdir, "test2.tif"), overwrite = TRUE)
    terra::writeRaster(ncelev, file.path(tdir, "test3.tif"), overwrite = TRUE)
    terra::writeRaster(ncelev, file.path(tdir, "test4.tif"), overwrite = TRUE)
    terra::writeRaster(ncelev, file.path(tdir, "test5.tif"), overwrite = TRUE)

    testfiles <- list.files(tdir, pattern = "tif$", full.names = TRUE)
    testthat::expect_no_error(
      res <- par_multirasters(
        filenames = testfiles,
        fun_dist = extract_at_poly,
        polys = nccnty,
        surf = ncelev,
        id = "GEOID",
        func = "mean"
      )
    )
    testthat::expect_s3_class(res, "data.frame")
    testthat::expect_true(!anyNA(res))

    testthat::expect_no_error(
      res <- par_multirasters(
        filenames = testfiles,
        fun_dist = extract,
        y = nccnty,
        x = ncelev,
        fun = mean
      )
    )

    testfiles_corrupted <- c(testfiles, "/home/runner/fallin.tif")
    testthat::expect_condition(
      resnas <- par_multirasters(
        filenames = testfiles_corrupted,
        fun_dist = extract_at_poly,
        polys = nccnty,
        surf = ncelev,
        id = "GEOID",
        func = "mean"
      )
    )

    testthat::expect_s3_class(resnas, "data.frame")
    testthat::expect_true(anyNA(resnas))

    # error case
    future::plan(future::sequential)
    testthat::expect_condition(
      resnasx <- par_multirasters(
        filenames = testfiles_corrupted,
        debug = TRUE,
        fun_dist = extract_at_poly,
        polys = nccnty,
        surf = ncelev,
        id = "GEOID",
        func = "mean"
      )
    )
  }
)

```


```{r, eval = FALSE, include = FALSE}
# @title Process a given function in the entire or partial computational grids using `furrr`
#' @family Parallelization
#' @description
#' [future::multicore], [future::multisession], [future::cluster]
#' with [doParallel::registerDoParallel] will parallelize the work
#' in each grid. For details of the terminology in \code{future} package,
#' refer to \link[future]{plan}. This function assumes that
#' users have one raster file and a sizable and spatially distributed
#' target locations. Each thread will process
#' the nearest integer of $|N_g| / |N_t|$ grids
#' where $|N_g|$ denotes the number of grids and $|N_t|$ denotes
#' the number of threads.
#' @note In dynamic dots (\code{...}), the first and second
#' arguments should be the \code{fun_dist} arguments where
#' sf/SpatVector objects are accepted.
#' Virtually any sf/terra functions that accept two arguments
#' can be put in \code{fun_dist}, but please be advised that
#' some spatial operations do not necessarily give the
#' exact result from what would have been done single-thread.
#' For example, distance calculated through this function may return the
#' lower value than actual because the computational region was reduced.
#' This would be the case especially where the target features
#' are spatially sparsely distributed.
#' @param grids sf/SpatVector object. Computational grids.
#'  It takes a strict assumption that the grid input is
#'  an output of \code{par_make_gridset}
#' @param grid_target_id character(1) or numeric(2).
#'  Default is NULL. If NULL, all grid_ids are used.
#'  \code{"id_from:id_to"} format or
#'  \code{c(unique(grid_id)[id_from], unique(grid_id)[id_to])}
#' @param debug logical(1). Prints error messages
#' if there were any errors during the calculation.
#' @param combine function. The function to combine the results.
#' Default is `dplyr::bind_rows`.
#' @param fun_dist `sf`, `terra` or `chopin` functions.
#' @param ... Arguments passed to the argument \code{fun_dist}.
#' The **second** place should get a vector or raster dataset from which
#' you want to extract or calculate values. For example, a raster dataset
#' when vector-raster overlay is performed.
#' @returns a data.frame object with computation results.
#'  For entries of the results, consult the function used in
#'  \code{fun_dist} argument.
#' @author Insang Song \email{geoissong@@gmail.com}
#' @examples
#' \dontrun{
#' ncpath <- system.file("shape/nc.shp", package = "sf")
#' ncpoly <- terra::vect(ncpath) |>
#'   terra::project("EPSG:5070")
#' ncpnts <-
#'   readRDS(
#'     system.file("extdata/nc_random_point.rds", package = "chopin")
#'   )
#' ncpnts <- terra::vect(ncpnts)
#' ncpnts <- terra::project(ncpnts, "EPSG:5070")
#' ncelev <-
#'   terra::unwrap(
#'     readRDS(system.file("extdata/nc_srtm15_otm.rds", package = "chopin"))
#'   )
#' terra::crs(ncelev) <- "EPSG:5070"
#' names(ncelev) <- c("srtm15")
#'
#' ncsamp <-
#'   terra::spatSample(
#'     terra::ext(ncelev),
#'     1e4L,
#'     lonlat = FALSE,
#'     as.points = TRUE
#'   )
#' ncsamp$kid <- sprintf("K-%05d", seq(1, nrow(ncsamp)))
#' nccompreg <-
#'   par_make_gridset(
#'     input = ncpnts,
#'     mode = "grid",
#'     nx = 6L,
#'     ny = 4L,
#'     padding = 3e4L
#'   )
#' res <-
#'   par_grid_furrr(
#'     grids = nccompreg,
#'     grid_target_id = NULL,
#'     fun_dist = extract_at_buffer,
#'     points = ncpnts,
#'     surf = ncelev,
#'     qsegs = 90L,
#'     radius = 5e3L,
#'     id = "pid"
#'   )
#' }
#' @import future
#' @import furrr
#' @importFrom future.apply future_lapply
#' @importFrom rlang inject
#' @importFrom rlang !!!
#' @importFrom dplyr bind_rows
#' @importFrom sf sf_use_s2
#' @export
par_grid_furrr <-
  function(
    grids,
    grid_target_id = NULL,
    debug = FALSE,
    combine = dplyr::bind_rows,
    furrr_opt =
    furrr::furrr_options(
      stdout = TRUE,
      conditions = "condition",
      globals = FALSE,
      packages = c("chopin", "dplyr", "sf", "terra", "furrr"),
      seed = 2024,
      scheduling = 2,
      chunk_size = NULL,
      prefix = NULL
    )
    ,
    fun_dist,
    ...
  ) {

    if (is.character(grid_target_id) && !grepl(":", grid_target_id)) {
      stop("Character grid_target_id should be in a form of 'startid:endid'.\n")
    }
    if (is.numeric(grid_target_id)) {
      if (length(grid_target_id) != 2) {
        stop(
          "Numeric grid_target_id should be in a form of c(startid, endid).\n"
        )
      }
      grid_target_ids <- unlist(grids$original[["CGRIDID"]])[grid_target_id]
    }
    # subset using grids and grid_id
    if (is.null(grid_target_id)) {
      grid_target_ids <- unlist(grids$original[["CGRIDID"]])
    }
    if (is.character(grid_target_id)) {
      grid_id_parsed <- strsplit(grid_target_id, ":", fixed = TRUE)[[1]]
      grid_target_ids <-
        c(which(unlist(grids$original[["CGRIDID"]]) == grid_id_parsed[1]),
          which(unlist(grids$original[["CGRIDID"]]) == grid_id_parsed[2]))
    }

    grids_target <-
      grids$original[grid_target_ids %in% unlist(grids$original[["CGRIDID"]]), ]
    grids_target_list <- split(grids_target, unlist(grids_target[["CGRIDID"]]))

    results_distributed <-
      grids_target_list |>
      furrr::future_map(
        .f =
        function(grid) {
          sf::sf_use_s2(FALSE)

          run_result <- tryCatch({
            args_input <- list(...)
            ## Strongly assuming that
            # the first is "at", the second is "from"
            args_input[[1]] <-
              args_input[[1]][grid, ]
            if (methods::is(args_input[[2]], "SpatVector")) {
              gpad_in <- grids$padded[grids$padded$CGRIDID == grid$CGRIDID, ]
              args_input[[2]] <- args_input[[2]][gpad_in, ]
            }
            if (!"id" %in% names(formals(fun_dist))) {
              args_input$id <- NULL
            }

            res <- rlang::inject(fun_dist(!!!args_input))
            cat(
              sprintf(
                "Your input function was successfully run at CGRIDID: %s\n",
                as.character(unlist(grid[["CGRIDID"]]))
              )
            )

            try(res <- as.data.frame(res))
            return(res)
          },
          error = function(e) {
            par_fallback(e, fun_dist, debug)

          })

          return(run_result)
        },
        .options = furrr_opt
      )
    results_distributed <- do.call(combine, results_distributed)

    return(results_distributed)
  }

```


```{r, include = FALSE, eval = FALSE}

qpart <- function(steps = 4L) {
  if (steps < 2L) {
    stop("steps should be greater than 1.")
  }
  quantiles <- seq(0, 1, length.out = steps + 1)
  return(quantiles)
}
qpart()


# Generate 1000 random points at a 100 by 100 plane
random_points <- data.frame(x = runif(1000, 0, 100), y = runif(1000, 0, 100))

cc <- par_cut_coords(random_points$x, random_points$y, qpart(4L))


partition_coordinates(random_points$x, random_points$y, kpart())

partition_coordinates <- function(x, y, quantiles) {
  x_quantiles <- quantile(x, probs = quantiles)
  y_quantiles <- quantile(y, probs = quantiles)
  
  x_partition <- cut(x, breaks = x_quantiles, labels = FALSE, include.lowest = TRUE)
  y_partition <- cut(y, breaks = y_quantiles, labels = FALSE, include.lowest = TRUE)
  
  return(list(x_partition = x_partition, y_partition = y_partition))
}

jj = as.data.frame(partition_coordinates(random_points$x, random_points$y, kpart())
)
jj$disting <- sprintf("%d%d", jj$x_partition, jj$y_partition)
plot(random_points$x, random_points$y, col = jj$disting)

```


```{r, eval = FALSE, include = FALSE}
adhoc <- function() {
  library(sf)
  library(terra)
  library(dplyr)
  library(future)
  library(future.apply)
  library(exactextractr)
  library(chopin)

  ncpath <- system.file("shape/nc.shp", package = "sf")
  ncpnts <-
    readRDS(system.file("extdata/nc_random_point.rds", package = "chopin"))
  ncpnts <- terra::vect(ncpnts)
  ncpnts <- terra::project(ncpnts, "EPSG:5070")
  ncelev <-
    terra::unwrap(
      readRDS(
        system.file("extdata/nc_srtm15_otm.rds", package = "chopin")
      )
    )
  terra::crs(ncelev) <- "EPSG:5070"
  names(ncelev) <- c("srtm15")

  nccompreg <-
    par_make_gridset(
      input = ncpnts,
      mode = "grid",
      nx = 6L,
      ny = 4L,
      padding = 3e4L
    )

  par_grid(
    grids = nccompreg,
    grid_target_id = NULL,
    fun_dist = extract_at_buffer,
    points = ncpnts,
    qsegs = 90L,
    surf = ncelev,
    radius = 5e3L,
    id = "pid"
  )

}
adhoc()


adhoc2 <- function() {
        library(sf)
  library(terra)
  library(dplyr)
  library(future)
  library(future.apply)
  library(exactextractr)
  library(chopin)

  ncpath <- system.file("shape/nc.shp", package = "sf")
  ncpoly <- terra::vect(ncpath) |>
    terra::project("EPSG:5070")
  ncpnts <- readRDS(system.file("extdata/nc_random_point.rds", package = "chopin"))
  ncpnts <- terra::vect(ncpnts)
  ncpnts <- terra::project(ncpnts, "EPSG:5070")
  ncelev <- terra::unwrap(readRDS(system.file("extdata/nc_srtm15_otm.rds", package = "chopin")))
  terra::crs(ncelev) <- "EPSG:5070"
  names(ncelev) <- c("srtm15")

  nccompreg <-
    par_make_gridset(
      input = ncpnts,
      mode = 'grid',
      nx = 6L,
      ny = 4L,
      padding = 3e4L)

      detected_id <- "pid"
      grids_target_list <- split(nccompreg$original, unlist(nccompreg$original[["CGRIDID"]]))
      future.apply::future_lapply(
      grids_target_list,
      \(x) {
        sf::sf_use_s2(FALSE)
        
        run_result <- tryCatch({
          res <- extract_at_buffer(ncpnts, ncelev, 5e3L, "pid")
          cat(sprintf("Your input function was 
          successfully run at CGRIDID: %s\n",
            
            as.character(unlist(x[["CGRIDID"]]))))
          
          return(res)
        },
        error = function(e) {
          fallback <- data.frame(ID = NA)
          colnames(fallback)[1] <- detected_id
          return(fallback)
        })
        
        return(run_result)
      },
      future.seed = TRUE,
      future.packages = c("terra", "sf", "dplyr", "chopin", "exactextractr"))
}
adhoc2()


extract_at_buffer(points = ncpnts, surf = ncelev, radius = 5e3L, qsegs = 90L, id = "pid")
exactextractr::exact_extract(ncelev, sf::st_as_sf(terra::buffer(ncpnts, 5e3L)), fun = "mean", force_df = TRUE)
```


```{r, eval = FALSE, include = FALSE}
bcsd_path <- system.file(package = "stars", "nc/bcsd_obs_1999.nc")
bcsd_stars <- stars::read_stars(bcsd_path)
```

## Documenting the package and building

We finish by running commands that will document, build, and install the package.  It may also be a good idea to check the package from within this file.

```{r run-devtools, eval = TRUE, results = "asis", message = TRUE, echo = TRUE}
litr::document()

# knitr::knit(
#   "./tools/vignettes-sources/v02_par.Rmd.orig",
#   output = "./tools/vignettes-sources/v02_par.Rmd"
#   )

# devtools::build(pkg = ".")
# knitr::knit(
#   "../tools/vignettes-sources/v02_par.Rmd.orig",
#   output = "./vignettes/v02_par.Rmd"
#   )
# cat(getwd())
# print(getwd())
```

```{r, eval = FALSE}
litr::add_pkgdown("../tools/pkgdown-source/_pkgdown.yml")
```


```{r comment=''}
cat(readLines("../tools/pkgdown-source/_pkgdown.yml"), sep = '\n')
```



```{r copy-prebuilt-figures, eval = FALSE}
# here we return to the current working directory "you see"
# for pre-built vignettes
if (dir.exists("../figures")) {
  if (!dir.exists("./vignettes/figures")) {
    dir.create("./vignettes/figures")
  }
  file.copy(from = "../figures", to = "./vignettes/figures", recursive = TRUE)
}

# pkgbuild::build(path = ".")
```

```{r, include = FALSE}
# When the build was stuck after major/minor function update and
# any vignette is changed, run below.
# knitr::knit(
#   "./tools/vignettes-sources/v02_par.Rmd.orig",
#   output = "./tools/vignettes-sources/v02_par.Rmd"
#   )

```

```{r post-hoc-cleaning, echo = F, eval = FALSE}
if (!dir.exists(getwd())) {
  dir.create(getwd())
}

gitpath = gsub("/chopin", "", getwd())

system("unalias cp")
system(paste0("cp -r ", getwd(), "/* ", gitpath))
Sys.sleep(1)
system(paste0("rm -r ", getwd()))

```


```{r, eval = FALSE}
system(paste0("cp -r ../chopin/* ."))
setwd("..")
Sys.sleep(1)
system("rm -r ./chopin")
Sys.sleep(1)
knitr::knit("./README.Rmd", "./README.md")
```

```{r post-hoc-manualrun, eval = FALSE}
# in interactive session
system(paste0("cp -r ./chopin/* ."))
system("rm -r ./chopin")
system("rm ./chopin_rmarkdown_litr.html")
# knit manually
devtools::build_readme()

codemetar::write_codemeta()
devtools::install(build_vignettes = TRUE)
devtools::check()

devtools::test()
covr::package_coverage()
```


## Multinode computation
```{r slurm-submission-template, eval = FALSE, include = FALSE}
# slurm submission is here

```
